{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лекция 3 (часть 1): Введение в глубокое обучение (2)\n",
    "\n",
    "__Автор: Сергей Вячеславович Макрушин__ e-mail: SVMakrushin@fa.ru \n",
    "\n",
    "Финансовый универсиет, 2021 г. \n",
    "\n",
    "При подготовке лекции использованы материалы:\n",
    "* ...\n",
    "\n",
    "* V 0.4 04.02.2021\n",
    "* V 0.5 09.03.2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ’®¬ ў гбва®©бвўҐ E Ё¬ҐҐв ¬ҐвЄг Data\n",
      " ‘ҐаЁ©­л© ­®¬Ґа в®¬ : EE2C-D1DD\n",
      "\n",
      " ‘®¤Ґа¦Ё¬®Ґ Ї ЇЄЁ E:\\YandexDisk\\Python\\Ipynb\\ML_DL_2021\\lec02b\n",
      "\n",
      "09.03.2021  01:16    <DIR>          .\n",
      "09.03.2021  01:16    <DIR>          ..\n",
      "04.02.2021  15:54    <DIR>          .ipynb_checkpoints\n",
      "04.02.2021  15:32    <DIR>          img\n",
      "04.11.2020  17:28             2я835 lec_v2.css\n",
      "09.03.2021  01:16            81я379 TCN20_lNNp1b_v4.ipynb\n",
      "               2 д ©«®ў         84я214 Ў ©в\n",
      "               4 Ї Ї®Є  336я003я940я352 Ў ©в бў®Ў®¤­®\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "﻿<style>\r\n",
       "\r\n",
       "\r\n",
       "b.n {\r\n",
       "    font-weight: normal;        \r\n",
       "}\r\n",
       "\r\n",
       "b.grbg {\r\n",
       "    background-color: #a0a0a0;      \r\n",
       "}\r\n",
       "\r\n",
       "b.r {\r\n",
       "    color: #ff0000;    \r\n",
       "}\r\n",
       "\r\n",
       "\r\n",
       "b.b {    \r\n",
       "    color: #0000ff;    \r\n",
       "}\r\n",
       "\r\n",
       "b.g {\r\n",
       "    color: #00ff00;    \r\n",
       "}\r\n",
       "\r\n",
       "\r\n",
       "// add your CSS styling here\r\n",
       "\r\n",
       "list-style: none;\r\n",
       "\r\n",
       "ul.s {\r\n",
       "//    list-style-type: none;\r\n",
       "    list-style: none;\r\n",
       "//    background-color: #ff0000;  \r\n",
       "//    color: #ffff00;\r\n",
       "//  padding-left: 1.2em;\r\n",
       "//  text-indent: -1.2em;\r\n",
       "}\r\n",
       "\r\n",
       "li.t {\r\n",
       "    list-style: none;\r\n",
       "//  padding-left: 1.2em;\r\n",
       "//  text-indent: -1.2em;    \r\n",
       "}\r\n",
       "\r\n",
       "\r\n",
       "*.r {\r\n",
       "    color: #ff0000;    \r\n",
       "}\r\n",
       "\r\n",
       "li.t:before {\r\n",
       "    content: \"\\21D2\";    \r\n",
       "//    content: \"►\";\r\n",
       "//    padding-left: -1.2em;    \r\n",
       "    text-indent: -1.2em;    \r\n",
       "    display: block;\r\n",
       "    float: left;\r\n",
       "    \r\n",
       "    \r\n",
       "//    width: 1.2em;\r\n",
       "//    color: #ff0000;\r\n",
       "}\r\n",
       "\r\n",
       "i.m:before {\r\n",
       "    font-style: normal;    \r\n",
       "    content: \"\\21D2\";  \r\n",
       "}\r\n",
       "i.m {\r\n",
       "    font-style: normal; \r\n",
       "}    \r\n",
       "\r\n",
       "/*--------------------*/\r\n",
       "/* em {\r\n",
       "    font-style: normal; \r\n",
       "} */\r\n",
       "\r\n",
       "\r\n",
       "em.bl {\r\n",
       "    font-style: normal;     \r\n",
       "    font-weight: bold;        \r\n",
       "}\r\n",
       "\r\n",
       "/* em.grbg {\r\n",
       "    font-style: normal;         \r\n",
       "    background-color: #a0a0a0;      \r\n",
       "} */\r\n",
       "\r\n",
       "em.cr {\r\n",
       "    font-style: normal;         \r\n",
       "    color: #ff0000;    \r\n",
       "}\r\n",
       "\r\n",
       "em.cb {    \r\n",
       "    font-style: normal;         \r\n",
       "    color: #0000ff;    \r\n",
       "}\r\n",
       "\r\n",
       "em.cg {\r\n",
       "    font-style: normal;         \r\n",
       "    color: #00ff00;    \r\n",
       "}\r\n",
       "\r\n",
       "/*--------------------*/\r\n",
       "\r\n",
       "em.qs {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.qs::before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #ff0000;    \r\n",
       "    content: \"Q:\";  \r\n",
       "}\r\n",
       "\r\n",
       "em.an {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.an:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #0000ff;    \r\n",
       "    content: \"A:\";  \r\n",
       "}\r\n",
       "    \r\n",
       "em.nt {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.nt:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #0000ff;    \r\n",
       "    content: \"Note:\";  \r\n",
       "}    \r\n",
       "    \r\n",
       "em.ex {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.ex:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #00ff00;    \r\n",
       "    content: \"Ex:\";  \r\n",
       "} \r\n",
       "    \r\n",
       "em.df {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.df:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #0000ff;    \r\n",
       "    content: \"Def:\";  \r\n",
       "}    \r\n",
       "\r\n",
       "em.pl {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.pl:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #0000ff;    \r\n",
       "    content: \"+\";  \r\n",
       "}    \r\n",
       "\r\n",
       "em.mn {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.mn:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #0000ff;    \r\n",
       "    content: \"-\";  \r\n",
       "}        \r\n",
       "\r\n",
       "em.plmn {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.plmn:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #0000ff;    \r\n",
       "    content: \"\\00B1\";\\\\\"&plusmn;\";  \r\n",
       "}\r\n",
       "    \r\n",
       "em.hn {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.hn:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #0000ff;    \r\n",
       "    content: \"\\21D2\";\\\\\"&rArr;\";  \r\n",
       "}     \r\n",
       "    \r\n",
       "\r\n",
       "#cssTableCenter td, th \r\n",
       "{\r\n",
       "    text-align: center; \r\n",
       "    vertical-align: middle;\r\n",
       "}\r\n",
       "\r\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# загружаем стиль для оформления презентации\n",
    "from IPython.display import HTML\n",
    "from urllib.request import urlopen\n",
    "html = urlopen(\"file:./lec_v2.css\")\n",
    "HTML(html.read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вторая весна ИИ и глубокое обучение <a class=\"anchor\" id=\"вторая-весна\"></a>\n",
    "* [к оглавлению](#разделы)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разделы: <a class=\"anchor\" id=\"разделы\"></a>\n",
    "* [Базовые понятия, персептрон](#персептрон)\n",
    "* [Современные методы обучения нейронной сети и обратное распространение ошибки](#современные-методы)\n",
    "* [Вторая весна ИИ и глубокое обучение](#вторая-весна)\n",
    "*  \n",
    "-\n",
    "\n",
    "* [к оглавлению](#разделы)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Алгоритмические достижения в области глубокого обучения__\n",
    "\n",
    "Кроме оборудования и данных, до конца 2000-х нам не хватало надежного способа обучения очень глубоких нейронных сетей, как результат:\n",
    "* нейронные сети оставались очень неглубокими, имеющими один или два слоя представления; \n",
    "* <em class=\"hn\"></em> они не могли противостоять более совершенным поверхностным методам (методу опорных векторов и случайные леса). Основная __проблема__ заключалась в __распространении градиента через глубокие пакеты слоев__. Сигнал обратной связи, используемый для обучения нейронных сетей, __затухает по мере увеличения количества слоев__.\n",
    "\n",
    "<center> \n",
    "    <img src=\"./img/ann_14.png\" alt=\"Приниципиальная логика обучения нейронной сети\" style=\"width: 370px;\"/>\n",
    "    <strong>Приниципиальная логика обучения нейронной сети</strong>     \n",
    "</center>\n",
    "\n",
    "В районе 2010 г. появились некоторые простые, но важных алгоритмические усовершенствования, позволившие улучшить распространение градиента:\n",
    "* __улчшенные подходы к регуляризации__\n",
    "* __улучшенные схемы инициализации весов__\n",
    "* __улучшенные функции активации__\n",
    "* __улучшенные схемы оптимизации__ (такие как RMSProp и Adam)\n",
    "\n",
    "В последнее время были открыты еще более совершенные способы распространения градиента, с применением которых появилась возможность обучать с нуля модели с тысячами слоев в глубину. В частонсти:\n",
    "* пакетная нормализация\n",
    "* обходные связи \n",
    "* отделимые свертки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Улчшенные подходы к регуляризации\n",
    "\n",
    "__Регуляризация в нейронных сетях__\n",
    "\n",
    "<center> \n",
    "    <img src=\"./img/deepnet_10.png\" alt=\"Проблема переобучения модели\" style=\"width: 500px;\"/>\n",
    "    <strong>Проблема переобучения модели</strong>     \n",
    "</center>\n",
    "\n",
    "* модель, у которой слишком много свободных параметров, __плохо обобщается__: то есть слишком близко «облизывает» точки из тренировочного множества и в результате недостаточно хорошо предсказывает нужные значения в новых точках. \n",
    "* В современных нейронных сетях огромное число параметров (даже не самая сложная архитектура может содержать миллионы весов) <em class=\"hn\"></em> __надо регуляризовать параметры__!\n",
    "\n",
    "<center> \n",
    "    <img src=\"./img/deepnet_11.png\" alt=\"Принцип регуляризации 1\" style=\"width: 500px;\"/>\n",
    "    <img src=\"./img/deepnet_12.png\" alt=\"Принцип регуляризации 2\" style=\"width: 500px;\"/>\n",
    "    <strong>Принцип регуляризации параметров модели</strong>     \n",
    "</center>\n",
    "\n",
    "* Наиболее распросранненные регуляризаторы:\n",
    "    * $L_2$-регуляризатор: сумма квадратов весов $\\lambda \\sum_w w^2$\n",
    "    * $L_1$-регуляризатор: сумма модулей весов $\\lambda \\sum_w |w|$\n",
    "* В теории нейронных сетей такая регуляризация называется сокращением весов eight decay), потому что действительно приводит к уменьшению их абсолютных значений.\n",
    "\n",
    "* в Keras есть возможность для каждого слоя добавить регуляризатор на три вида связей:\n",
    "    * ```kernel_regularizer``` — на матрицу весов слоя;\n",
    "    * ```bias_regularizer``` — на вектор свободных членов;\n",
    "    * ```activity_regularizer``` — на вектор выходов.\n",
    "\n",
    "Пример L1 и L2 регуляризациия в Keras:\n",
    "```python\n",
    "model.add(Dense(256, input_dim=32,\n",
    "kernel_regularizer=regularizers.l1(0.001),\n",
    "bias_regularizer=regularizers.l2(0.1),\n",
    "activity_regularizer=regularizers.l2(0.01)))\n",
    "```\n",
    "\n",
    "Пример использования L1 и L2 регуляризациия в PyTorch:\n",
    "```python\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[8.5743e-01, 1.6870e-01, 2.9518e-01, 1.0505e-01, 3.6223e-01, 2.1123e-02,\n",
      "         2.2324e-01, 7.9837e-01, 3.8956e-02, 2.9797e-01, 1.9440e-01, 7.5391e-01,\n",
      "         7.0698e-01, 6.5929e-01, 2.1607e-01, 6.1403e-01, 1.0767e-01, 1.3382e-01,\n",
      "         5.1843e-01, 9.4934e-02, 5.4587e-01, 7.9665e-01, 2.2471e-01, 7.0374e-01,\n",
      "         7.8050e-01, 3.1299e-01, 2.9825e-01, 1.6610e-02, 6.2346e-01, 6.4508e-03,\n",
      "         5.2963e-01, 1.0553e-01, 2.3941e-01, 7.9415e-01, 7.0735e-01, 9.5080e-01,\n",
      "         7.0562e-01, 9.4920e-01, 2.2592e-01, 9.4089e-01, 8.9842e-01, 4.2875e-01,\n",
      "         3.0319e-01, 3.7566e-01, 8.8388e-01, 2.0469e-01, 9.1138e-01, 9.4556e-01,\n",
      "         3.6575e-02, 5.4808e-02, 6.3220e-01, 1.6812e-01, 9.9315e-01, 3.4655e-01,\n",
      "         1.3394e-01, 4.5229e-01, 2.4653e-01, 2.2065e-01, 3.0000e-01, 7.0977e-02,\n",
      "         9.5425e-01, 2.4142e-01, 6.8734e-01, 3.4597e-01, 7.6702e-01, 6.7419e-01,\n",
      "         4.7191e-01, 5.2325e-03, 7.8265e-01, 5.8902e-02, 2.1579e-01, 3.4284e-01,\n",
      "         4.4070e-01, 1.1715e-01, 9.5302e-01, 6.8159e-01, 1.8979e-01, 5.3829e-01,\n",
      "         7.9578e-01, 5.5640e-01, 9.7457e-01, 3.4837e-01, 2.9860e-01, 3.5824e-01,\n",
      "         2.1319e-01, 5.6449e-02, 2.6548e-01, 6.1974e-01, 4.2227e-01, 2.5299e-01,\n",
      "         2.3600e-01, 4.7427e-01, 1.1021e-01, 1.8941e-02, 4.6775e-02, 8.3458e-01,\n",
      "         8.9713e-01, 3.6094e-01, 9.5748e-01, 9.9902e-01, 5.9690e-02, 2.4872e-01,\n",
      "         1.2048e-01, 2.8546e-01, 5.9334e-01, 9.0655e-01, 8.7248e-01, 1.9547e-01,\n",
      "         4.6610e-01, 3.2712e-01, 8.2912e-01, 4.1999e-01, 7.2062e-01, 9.2537e-01,\n",
      "         5.1409e-02, 1.1541e-01, 2.2983e-01, 8.5950e-01, 1.3904e-01, 5.3606e-01,\n",
      "         3.9415e-02, 2.0294e-01, 5.7497e-01, 8.7886e-01, 4.1134e-01, 7.5996e-01,\n",
      "         8.6215e-01, 3.5199e-01],\n",
      "        [5.5223e-02, 9.1701e-01, 5.7805e-01, 6.8079e-01, 6.9990e-01, 5.7057e-01,\n",
      "         1.8177e-01, 9.2226e-02, 9.1474e-01, 1.4892e-01, 2.5016e-02, 7.9692e-01,\n",
      "         7.6213e-02, 1.3749e-01, 3.6411e-01, 3.3977e-01, 1.5965e-01, 4.9990e-01,\n",
      "         1.5207e-01, 1.4134e-01, 2.5271e-02, 9.1633e-01, 5.3529e-01, 4.7454e-01,\n",
      "         2.7687e-01, 1.5861e-01, 6.3792e-01, 6.0924e-01, 1.0588e-02, 2.1777e-01,\n",
      "         5.6442e-01, 7.8395e-01, 6.2918e-01, 9.4276e-01, 2.7341e-01, 7.7639e-01,\n",
      "         8.7313e-01, 4.1172e-01, 7.9629e-01, 7.9613e-01, 3.4602e-01, 9.6120e-01,\n",
      "         4.6114e-01, 6.7652e-01, 3.2054e-01, 2.6104e-01, 6.4330e-01, 7.2663e-01,\n",
      "         1.4056e-01, 1.6872e-01, 3.8088e-01, 3.7632e-01, 3.3306e-01, 2.1738e-02,\n",
      "         7.5907e-01, 1.3722e-01, 1.3060e-01, 9.7964e-01, 1.3910e-01, 6.1337e-01,\n",
      "         6.0021e-01, 4.1671e-02, 1.7463e-01, 1.7793e-01, 3.6736e-01, 5.5861e-01,\n",
      "         5.0010e-01, 8.3285e-01, 3.6037e-01, 4.2339e-02, 7.6650e-01, 9.7419e-01,\n",
      "         9.0384e-01, 7.7493e-01, 4.0057e-01, 2.9587e-01, 9.2248e-01, 9.6056e-01,\n",
      "         1.3000e-01, 7.7495e-01, 9.8991e-01, 8.0551e-01, 1.0785e-02, 7.1276e-01,\n",
      "         4.6209e-01, 1.6211e-01, 1.2724e-01, 9.9060e-01, 5.5970e-01, 1.2364e-01,\n",
      "         9.8967e-01, 5.6902e-01, 2.8364e-01, 1.8417e-01, 9.3584e-01, 2.1991e-01,\n",
      "         3.9550e-01, 6.9330e-01, 3.4359e-01, 7.0945e-01, 5.5624e-01, 1.4778e-01,\n",
      "         4.1216e-02, 3.8240e-01, 3.0506e-01, 5.4315e-01, 8.8294e-01, 2.9101e-01,\n",
      "         7.5029e-01, 4.6238e-01, 4.7890e-01, 7.5000e-02, 3.0856e-01, 7.7893e-01,\n",
      "         8.0638e-01, 8.8063e-01, 2.5311e-01, 7.7799e-01, 7.5171e-01, 3.3763e-01,\n",
      "         7.8571e-01, 8.8732e-01, 8.5823e-01, 7.4403e-01, 6.5548e-01, 8.4956e-02,\n",
      "         3.3493e-01, 1.4176e-01],\n",
      "        [9.4457e-01, 7.9514e-01, 3.9100e-01, 5.5226e-01, 1.2001e-01, 7.5797e-01,\n",
      "         3.9644e-01, 6.6044e-01, 4.3999e-01, 2.7817e-01, 2.6439e-01, 1.5852e-01,\n",
      "         8.0373e-01, 5.0267e-01, 8.7537e-01, 7.0298e-01, 2.2127e-01, 3.5883e-01,\n",
      "         5.5566e-01, 1.4704e-01, 7.2109e-01, 7.5762e-01, 3.1374e-01, 2.6644e-01,\n",
      "         3.5467e-01, 4.7801e-01, 4.0975e-01, 3.8416e-02, 3.0777e-02, 3.1933e-01,\n",
      "         6.8963e-01, 9.1839e-01, 5.4277e-02, 6.4431e-01, 6.4150e-01, 5.4844e-01,\n",
      "         2.1049e-03, 6.8479e-01, 5.4075e-01, 9.3367e-01, 7.5161e-02, 7.9629e-01,\n",
      "         2.1447e-01, 2.3482e-01, 9.6496e-01, 3.9298e-01, 3.1552e-01, 6.4769e-02,\n",
      "         2.5219e-01, 8.4134e-01, 9.1816e-01, 5.0230e-01, 2.7649e-01, 5.8283e-01,\n",
      "         6.4756e-01, 7.9848e-01, 7.3704e-01, 2.9431e-01, 3.5752e-01, 3.2408e-01,\n",
      "         1.5827e-01, 4.4937e-01, 7.9951e-01, 7.0305e-01, 6.1699e-02, 7.6526e-01,\n",
      "         5.6817e-01, 7.9190e-01, 8.1632e-01, 9.7160e-01, 5.9687e-01, 3.8439e-01,\n",
      "         6.3075e-02, 2.7440e-01, 8.5746e-01, 9.9556e-01, 7.1896e-01, 7.9134e-01,\n",
      "         2.1508e-02, 7.3248e-02, 3.0225e-01, 6.6915e-01, 7.7116e-04, 9.8917e-01,\n",
      "         5.7344e-01, 3.8487e-01, 3.7591e-01, 6.0725e-01, 4.7911e-01, 3.1226e-01,\n",
      "         5.3548e-01, 9.6256e-01, 2.1860e-01, 6.7347e-01, 8.3305e-01, 3.8909e-01,\n",
      "         3.2924e-01, 3.1974e-01, 4.1272e-01, 3.9209e-01, 2.9767e-02, 3.1964e-01,\n",
      "         5.6400e-01, 2.9857e-01, 1.2886e-01, 5.1487e-01, 6.9829e-01, 5.5896e-02,\n",
      "         5.3005e-01, 8.1168e-01, 1.2631e-01, 4.1390e-01, 5.7733e-01, 2.4248e-01,\n",
      "         5.9111e-01, 3.8007e-02, 9.4707e-01, 4.6933e-01, 4.9265e-01, 8.4958e-01,\n",
      "         5.2458e-01, 3.4862e-01, 6.5988e-01, 4.6724e-01, 4.7791e-01, 4.1555e-01,\n",
      "         1.8537e-02, 3.6124e-01],\n",
      "        [7.2281e-01, 2.6549e-01, 9.8180e-01, 8.7137e-01, 2.2007e-01, 7.3045e-01,\n",
      "         3.3397e-01, 6.6870e-01, 6.7368e-01, 6.5207e-01, 9.3500e-01, 7.0172e-01,\n",
      "         2.7630e-01, 4.2237e-01, 9.2380e-01, 9.0922e-01, 6.0860e-01, 4.7393e-01,\n",
      "         2.9831e-01, 6.3339e-01, 8.3410e-01, 9.7466e-01, 9.3597e-01, 9.0428e-01,\n",
      "         2.5158e-01, 8.0467e-02, 8.8620e-01, 3.5361e-01, 1.2278e-01, 6.0828e-01,\n",
      "         6.4615e-01, 1.5041e-01, 3.8552e-01, 1.3356e-01, 6.1921e-01, 5.7030e-02,\n",
      "         7.3112e-01, 8.4149e-02, 1.5454e-02, 7.5618e-01, 7.1625e-01, 6.9025e-01,\n",
      "         5.6751e-01, 7.0349e-01, 5.3304e-01, 7.5510e-02, 7.3271e-02, 9.4489e-01,\n",
      "         5.6886e-01, 1.7816e-01, 9.9485e-01, 9.5597e-01, 7.3170e-01, 6.6845e-01,\n",
      "         4.8499e-01, 9.7830e-02, 1.5595e-01, 2.5994e-02, 6.2394e-01, 4.0439e-01,\n",
      "         2.3868e-01, 8.1890e-01, 2.6572e-01, 4.6092e-01, 3.7320e-01, 7.2653e-02,\n",
      "         8.2954e-02, 1.3489e-01, 2.7767e-01, 1.0738e-01, 6.4174e-01, 5.7213e-01,\n",
      "         4.5063e-01, 1.2165e-01, 7.6923e-01, 1.1009e-02, 6.3956e-01, 1.0650e-01,\n",
      "         9.6490e-01, 2.7652e-01, 6.4803e-01, 2.0897e-01, 5.1147e-01, 1.7097e-01,\n",
      "         5.3736e-01, 6.7604e-01, 4.3779e-01, 8.3697e-01, 2.4945e-01, 2.2750e-02,\n",
      "         8.9192e-01, 4.1339e-01, 7.9321e-01, 5.0266e-01, 5.3304e-01, 2.2840e-01,\n",
      "         8.4394e-01, 8.4361e-01, 6.2511e-02, 7.0378e-01, 9.8606e-01, 8.2979e-01,\n",
      "         3.9061e-01, 8.6544e-01, 2.9624e-01, 9.5104e-01, 3.4549e-01, 5.5988e-01,\n",
      "         9.6000e-01, 8.6927e-01, 1.4204e-01, 1.6942e-01, 6.0429e-01, 1.6365e-01,\n",
      "         1.4122e-01, 8.6425e-02, 7.0194e-01, 6.7895e-01, 8.2103e-01, 8.3042e-01,\n",
      "         9.9832e-01, 7.8873e-02, 7.4615e-01, 9.8577e-01, 8.7176e-01, 3.4308e-01,\n",
      "         9.4285e-02, 5.9853e-01]])\n",
      "tensor([1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(128, 32)\n",
    "        self.linear2 = torch.nn.Linear(32, 16)\n",
    "        self.linear3 = torch.nn.Linear(16, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        layer1_out = F.relu(self.linear1(x))\n",
    "        layer2_out = F.relu(self.linear2(layer1_out))\n",
    "        out = self.linear3(layer2_out)\n",
    "        return out, layer1_out, layer2_out\n",
    "\n",
    "batchsize = 4\n",
    "lambda1, lambda2 = 0.5, 0.01\n",
    "\n",
    "model = MLP()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)\n",
    "\n",
    "# usually following code is looped over all batches \n",
    "# but let's just do a dummy batch for brevity\n",
    "\n",
    "inputs = Variable(torch.rand(batchsize, 128))\n",
    "print(inputs)\n",
    "targets = Variable(torch.ones(batchsize).long())\n",
    "\n",
    "\n",
    "optimizer.zero_grad()\n",
    "outputs, layer1_out, layer2_out = model(inputs)\n",
    "cross_entropy_loss = F.cross_entropy(outputs, targets)\n",
    "\n",
    "all_linear1_params = torch.cat([x.view(-1) for x in model.linear1.parameters()])\n",
    "all_linear2_params = torch.cat([x.view(-1) for x in model.linear2.parameters()])\n",
    "l1_regularization = lambda1 * torch.norm(all_linear1_params, 1)\n",
    "l2_regularization = lambda2 * torch.norm(all_linear2_params, 2)\n",
    "\n",
    "loss = cross_entropy_loss + l1_regularization + l2_regularization\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Регуляризация с помощью ранней остановки__ (early stopping)\n",
    "\n",
    "* Отложим часть тренировочного набора (назовем отложенную часть __валидационным множеством__).\n",
    "* При обучении на тренировочном множестве будем  вычислять ошибку и на валидационном множестве\n",
    "* Можно предположить, что  __ошибка на валидационном множестве будет хорошо оценивать ошибку и на новых точках__ (тестовом множестве), ведь она взята из данных той же природы, но тех, на которых мы не обучались.\n",
    "* Остановить обучение нужно будет не тогда, когда сеть прийдет в локальный оптимум для тренировочного множества, а тогда, __когда начнет ухудшаться ошибка на валидационном множестве__. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Регуляризации нейронных сетей с помощью дропаута__\n",
    "\n",
    "* __Регуляризация с помощью дропаута__ (dropout regularization) - один из важнейших методов регуляризации нейронных сетей обеспечивший революцию глубокого обучения\n",
    "\n",
    "Идея метода (очень простая!):\n",
    "* Для каждого нейрона (кроме самого последнего, выходного слоя) установим некоторую вероятность $p$, с которой он будет выброшен из сети.\n",
    "* Алгоритм обучения меняется таким образом: \n",
    "    * на каждом новом тренировочном примере $x$ мы сначала для каждого __разыгрываем вероятность $p$__ и в зависимости от результата либо используем нейрон как обычно, __либо устанавливаем его выход всегда строго равным нулю__ (вероятность этого события $1-p$). \n",
    "    * __Дальше все происходит без изменений__; ноль на выходе приводит к тому, что нейрон фактически выпадает из графа вычислений: и прямое вычисление, и обратное распространение градиента останавливаются на этом нейроне и дальше не идут.\n",
    "    * Для применения обученной сети __используются все нейроны__ в конфигурации, которая была до применения дропаута, но __выход каждого нейрона умножается на вероятность $p$__ (с которой нейрон оставляли при обучении).\n",
    "* Для очень широкого спектра архитектур и приложений замечательно подходит $p = 1/2$    \n",
    "\n",
    "<center> \n",
    "    <img src=\"./img/deepnet_13.png\" alt=\"Пример дропаута\" style=\"width: 500px;\"/>\n",
    "    <strong>Пример дропаута</strong>     \n",
    "</center>    \n",
    "\n",
    "* Практика обучения нейронных сетей показывает, что дропаут действительно дает очень серьезные улучшения в качестве обученной модели\n",
    "* Дропаут — это метод добиться __усреднения огромного чмсла моделей__  (до $2^N$ возможных моделей, $N$ — число нейронов, которые подвергаются дропауту). Он эквивалентен усреднению всех моделей, которые получались на каждом шаге случайным выбрасыванием отдельных нейронов.\n",
    "\n",
    "Пример использования Dropout в Keras:\n",
    "```python\n",
    "def create_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "    # Dropout:\n",
    "\tmodel.add(Dropout(0.2, input_shape=(60,)))\n",
    "\tmodel.add(Dense(60, kernel_initializer='normal', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "\tmodel.add(Dense(30, kernel_initializer='normal', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "\tmodel.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "\t# Compile model\n",
    "\tsgd = SGD(lr=0.1, momentum=0.9, decay=0.0, nesterov=False)\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\treturn model\n",
    "```\n",
    "\n",
    "Пример использования Dropout в PyTorch:\n",
    "```python\n",
    "def __init__(self, rnn_type, input_size, node_fdim, hidden_size, depth, dropout):\n",
    "        super(MPNEncoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.depth = depth\n",
    "        self.W_o = nn.Sequential( \n",
    "                nn.Linear(node_fdim + hidden_size, hidden_size), \n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "        if rnn_type == 'GRU':\n",
    "            self.rnn = GRU(input_size, hidden_size, depth) \n",
    "        elif rnn_type == 'LSTM':\n",
    "            self.rnn = LSTM(input_size, hidden_size, depth) \n",
    "        else:\n",
    "            raise ValueError('unsupported rnn cell type ' + rnn_type)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Улучшенные схемы инициализации весов\n",
    "\n",
    "* Обучение сети — сложная задача оптимизации в пространстве очень высокой размерности, которая фактически решается методами локального поиска.\n",
    "* Для таких задач один из ключевых вопросов: __где начинать этот локальный поиск?__\n",
    "    \n",
    "<center> \n",
    "    <img src=\"./img/ann_15.png\" alt=\"Пример работы градиентного спуска\" style=\"width: 500px;\"/>\n",
    "    <strong>Пример работы градиентного спуска для функции двух переменных</strong>     \n",
    "</center>    \n",
    "\n",
    "* Качество начального приближения приниципиально влияет на получаемые в результате локальные оптимумы.\n",
    "* Хорошая инициализация весов может позволить нам обучать глубокие сети:\n",
    "    * лучше (в смысле метрик качества)\n",
    "    * быстрее (в смысле числа требующихся обновлений весов, т.е. числа итераций, т.е. времени обучения)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первая идея, которая привела к большим успехам в этом направлении: __предобучение без учителя__ (unsupervised pretraining):\n",
    "* отдельные слои глубокой сети последовательно обучаются без учителя\n",
    "* затем веса полученных слоев считаются начальным приближением и дообучаются уже на размеченном наборе данных\n",
    "\n",
    "* сначала основным инструментом для предобучения без учителя в стали так называемые __ограниченные машины Больцмана__\n",
    "* затем для этого стали использоваться __автокодировщики__\n",
    "\n",
    "Основные приниципы испльзующиеся при предобучении:\n",
    "1. Предобучение слоев происходит последовательно, от нижних к верхним. \n",
    "    * позволяет избежать проблемы затухающих градиентов\n",
    "    * существенно уменьшает объем вычислений на каждом этапе\n",
    "2. Предобучение протекает без учителя, то есть без учета имеющихся размеченных данных.\n",
    "    * это часто позволяет существенно расширить обучающую выборку (например, собрать миллионы изображений из интернета без описания наманого проще, чем собрать даже тысячу правильно размеченных изображений).\n",
    "3. В результате предобучения получается модель, которую затем нужно дообучить на размеченных данных. \n",
    "    * модели, обученные таким образом, в конечном счете стабильно сходятся к существенно лучшим решениям, чем при случайной инициализации.\n",
    "\n",
    "Но:\n",
    "* сейчас на практике предварительное послойное обучение проводится редко, т.к. был найдены более простой и хорошо мотивированный способ инициализации весов, позволяющий существенно ускорить обучение и улучшить качество, его часто называют инициализацией Ксавье (Xavier initialization)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Инициализация Ксавье__\n",
    "\n",
    "Общий вид перцептрона:\n",
    "$$\\hat{y} = f(z) = f(w_0 + w_1 x_1 + \\ldots + w_n x_n) = f (\\mathbf{w}^T \\mathbf{x})$$, \n",
    "где $\\mathbf{x}=(1, x_1, \\ldots, x_n)$\n",
    "Т.е. $z=\\mathbf{w}^T \\mathbf{x}$\n",
    "\n",
    "Т.е. дисперсия $\\operatorname{Var}(z)$ не зависит от свободного члена $w_0$b и выражается через дисперсии $\\mathbf{x'}=(x_1, \\ldots, x_n)$ и $\\mathbf{w'}=(w_1, \\ldots, w_n)$. \n",
    "\n",
    "Для $z_i = w_i \\cdot x_i$, в предположении о том, что $w_i$ и $x_i$ независимы (что вполне естественно), мы получим дисперсию:\n",
    "$$\\operatorname{Var}(z_i)= \\operatorname{Var}(w_i \\cdot x_i) = \\mathbb{E} \\left [ x_i^2 w_i^2 \\right ] - \\left ( \\mathbb{E}  [ x_i w_i ] \\right ) ^2  = \\mathbb{E} \\left [ x_i^2 \\right ] \\mathbb{E} \\left [ w_i^2 \\right ] -  \\mathbb{E}  [ w_i ] ^2 \\mathbb{E}  [ w_i ] ^2 = \\left ( \\operatorname{Var}(x_i) + \\mathbb{E}  [ x_i ] ^2  \\right ) \\left ( \\operatorname{Var}(w_i) + \\mathbb{E}  [ w_i ] ^2 \\right ) -  \\mathbb{E}  [ x_i ] ^2 \\mathbb{E}  [ w_i ] ^2 = \\mathbb{E}  [ x_i ] ^2 \\operatorname{Var}(w_i) + \\mathbb{E}  [ w_i ] ^2 \\operatorname{Var}(x_i)  + \\operatorname{Var}(x_i) \\operatorname{Var}(w_i)$$\n",
    "\n",
    "Если мы используем симметричные функции активации и случайно инициализируем веса со средним значением, равным нулю, то первые два члена последнего выражения оказываются тоже равными нулю, а значит:\n",
    "\n",
    "$$\\operatorname{Var}(z_i) = \\operatorname{Var}(x_i) \\operatorname{Var}(w_i)$$\n",
    "\n",
    "Если теперь мы предполагаем, что как $x_i$, так и $w_i$ инициализируются из одного и того же распределения, причем независимо друг от друга (это сильное предположение, но в данном случае вполне естественное), мы получим:\n",
    "\n",
    "$$\\operatorname{Var}(z) = \\operatorname{Var} \\left ( \\sum_{i=1}^{n_{out}} z_i \\right ) = \\sum_{i=1}^{n_{out}} \\operatorname{Var}(x_i w_i) = n_{out} \\operatorname{Var}(x_i) \\operatorname{Var}(w_i)\\text{ ,}$$\n",
    "\n",
    "где $n_{out}$ — число нейронов последнего слоя. Другими словами, дисперсия выходов пропорциональна дисперсии входов с коэффициентом $n_{out} \\operatorname{Var}(w_i)$.\n",
    "\n",
    "Ранее стандартным эвристическим способом случайно инициализировать веса новой сети1 было равномерное распределение следующего вида:\n",
    "\n",
    "$$w_i \\sim U \\left [ -\\frac{1}{\\sqrt{n_{out}}}, \\frac{1}{\\sqrt{n_{out}}} \\right ]$$\n",
    "\n",
    "В этом случае получается, что:\n",
    "\n",
    "$$\\operatorname{Var}(w_i) = \\frac{1}{12} \\left ( \\frac{1}{\\sqrt{n_{out}}} + \\frac{1}{\\sqrt{n_{out}}} \\right ) ^2 = \\frac{1}{3 \\cdot n_{out}}\\text{ ,}$$\n",
    "тогда: $n_{out} \\operatorname{Var}(w_i)=\\frac{1}{3}$.\n",
    "\n",
    "* После нескольких слоев такое преобразование параметров распределения значений между слоями сети фактически __приводит к затуханию сигнала__: дисперсия результата слоя каждый раз уменьшается (фактически делится на 3), а среднее у него было нулевое.\n",
    "\n",
    "* Аналогичная ситуация повторяется и на шаге обратного распространения ошибки при обучении. \n",
    "\n",
    "* Если мы используем симметричную функцию активации с единичной производной в окрестности нуля (например, $\\tanh$), то теперь мы получим коэффициент пропорциональности для дисперсии $n_{in} \\operatorname{Var}(w_i)$, где $n_{in}$ - число нейронов во входном слое, а не на выходе.\n",
    "\n",
    "\n",
    "* Идея инициализации Ксавье заключается в том, что для беспрепятственного распространения значений активации и градиента по сети дисперсия в обоих случаях должна быть примерно равна единице.\n",
    "\n",
    "* Поскольку для неодинаковых размеров слоев невозможно удовлетворить оба условия одновременно, предлагается инициализировать веса очередного слоя сети симметричным распределением с такой дисперсией:\n",
    "$$ \\operatorname{Var}(w_i) = \\frac {2}{n_{in} + n_{out}}$$\n",
    "\n",
    "что для равномерной инициализации приводит к следующему распределению:\n",
    "\n",
    "$$w_i \\sim U \\left [ -\\frac{\\sqrt{6}}{\\sqrt{n_{in}+n_{out}}}, \\frac{\\sqrt{6}}{\\sqrt{n_{in}+n_{out}}} \\right ]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример использования в PyTorch:\n",
    "```python\n",
    "conv1 = torch.nn.Conv2d(...)\n",
    "torch.nn.init.xavier_uniform(conv1.weight)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Пример на Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# загрузка исходных данных:\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# правильные ответы заданы в виде цифр, придется перекодировать их в виде векторов:\n",
    "from keras.utils import np_utils\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь осталось для удобства переведем матрицы X_train и X_test из целочисленных значений на отрезке [0, 255] к вещественным на [0, 1] (нормализовать), а также сделать из квадратных изображений размера 28 × 28 пикселов одномер-\n",
    "ные векторы длины 784; это значит, что сами тензоры X_train и X_test будут иметь\n",
    "размерность (число примеров) × 784:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape([-1, 28*28]) / 255.\n",
    "X_test = X_test.reshape([-1, 28*28]) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(init):\n",
    "    '''init - екстовый параметр, который интерпретируется как тип инициализации \n",
    "    (для нашего эксперимента это будут значения uniform и glorot_normal)\n",
    "    Функция возвращает функция простую полносвязную модель с четырьмя промежуточными слоями, каждый из 100 нейронов.'''\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, input_shape=(28*28,), init=init, activation='tanh'))\n",
    "    model.add(Dense(100, init=init, activation='tanh'))\n",
    "    model.add(Dense(100, init=init, activation='tanh'))\n",
    "    model.add(Dense(100, init=init, activation='tanh'))\n",
    "    model.add(Dense(10, init=init, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniform_model = create_model(\"uniform\")\n",
    "uniform_model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "uniform_model.fit(x_train, Y_train, \n",
    "                  batch_size=64, nb_epoch=30, verbose=1, validation_data=(x_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glorot_model = create_model(\"glorot_normal\")\n",
    "glorot_model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "glorot_model.fit(x_train, Y_train, \n",
    "                 batch_size=64, nb_epoch=30, verbose=1, validation_data=(x_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> \n",
    "    <img src=\"./img/deepnet_14.png\" alt=\"Сравнение инициализаций\" style=\"width: 500px;\"/>\n",
    "    <strong>Сравнение инициализация Ксавьев и случайной инциализации весов</strong>     \n",
    "</center>  \n",
    "\n",
    "* Видно, что при инициализации весов по методу Ксавье модель уже после первой эпохи находит решение с точностью около 90 %, на что модели, чьи веса инициализированы равномерным распределением, требуется около 10 эпох. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нормализация по мини-батчам\n",
    "\n",
    "При обучении нейронных сетей один шаг градиентного спуска обычно делается не на одной точке входных данных, а на __мини-батче__, то есть на небольшой коллекции данных, которая обычно выбирается из всего обучающего множества случайно. С точки зрения оптимизации у такого подхода есть сразу несколько преимуществ.\n",
    "\n",
    "<center> \n",
    "    <img src=\"./img/ann_15.png\" alt=\"Пример работы градиентного спуска\" style=\"width: 500px;\"/>\n",
    "    <strong>Пример работы градиентного спуска для функции двух переменных</strong>     \n",
    "</center>\n",
    "\n",
    "__Стохастический градиентный спуск__\n",
    "\n",
    "* Шаг метода градиентного спуска:\n",
    "$$\\mathbf{w}^{t+1} = \\mathbf{w}_{t}-\\gamma\\nabla_{\\mathbf{w}} E(\\mathbf{w}^{t-1}) = \\mathbf{w}_{t}-\\gamma \\sum_{(\\mathbf{x}, \\mathbf{y}) \\in D} \\nabla_\\theta E(f_L(\\mathbf{x}, \\mathbf{w}^{t-1}), \\mathbf{y})$$\n",
    "* Выполнение на каждом шаге градиентого спуска суммирования по всем $(\\mathbf{x}, \\mathbf{y}) \\in D$ происходит слишком долго\n",
    "* Создаем батчи - случайные наборы из фиксированного количества элементов выборки (например $M$ элементов) $D^M$, $D^M \\subset D$ ($|D|=N$):\n",
    "$$\\nabla_{\\mathbf{w}} E(\\mathbf{w}^{t-1}) \\approx \\frac{N}{M}\\sum_{(\\pmb{x}, \\pmb{y}) \\in D^M} \\nabla_\\theta E(f_L(\\mathbf{x}, \\mathbf{w}^{t-1}), \\mathbf{y})$$\n",
    "\n",
    "Это работает, т.к.:\n",
    "* Т.к. обычно поверхность:\n",
    "    * не является квадратичной функцией\n",
    "    * не выпуклая \n",
    "    * имеет очень высокую размерность \n",
    "* Обчно наборы данных слишком большие, чтобы вычислять градиенты полностью\n",
    "* Нет никаких гарантий, что:\n",
    "    * итоговое решение будет хорошим\n",
    "    * решение быстро сходится к итоговому решению\n",
    "    * или, что оно вообще сходится \n",
    "\n",
    "Положительные свойства использования стохастического градиента:\n",
    "* работает намного быстрее чем ГС\n",
    "* на практике точность результата выше чем у ГС\n",
    "* мини-батчи позволяют работать с наборами данных, которые меняются со временем\n",
    "* дисперсия градиента возрастает при убывании размера батча ($\\sim 1/\\sqrt{M}$)\n",
    "\n",
    "<center> \n",
    "    <img src=\"./img/ann_20.png\" alt=\"Пример\" style=\"width: 400px;\"/>\n",
    "    <strong>Пример успешной работы стохастического градиентного спуска</strong>     \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Усреднение градиента по нескольким примерам__ представляет собой апроксимацию градиента по всему тренировочному множеству, и чем больше примеров используется в одном мини-батче, тем точнее это приближение. \n",
    "    * Максимальная точность достигается на шаге сразу на всем тренировочном датасете, но это слишком затратно вычислительно. \n",
    "* Глубокие нейронные сети подразумевают большое количество последовательных действий с каждым примером. GPU (и многоядерные CPU) позволяет эту длинную последовательность __рассчитывать параллельно__ для большого количества примеров.\n",
    "\n",
    "__Проблема внутреннего сдвига переменных (internal covariance shift) при глубоком обучении:__. \n",
    "* Если на очередном шаге градиентного спуска меняются веса одного из первых (нижних) слоев\n",
    "* <em class=\"hn\"></em> измененяются распределения активаций выходов этого слоя\n",
    "* <em class=\"hn\"></em> всем последующим слоям надо адаптироваться к новому распределеннию входных данных \n",
    "\n",
    "Пример:\n",
    "\n",
    "Пусть иммеется нейрон первого слоя:\n",
    "$$y = \\tanh (w_0 + w_1 x_1 + w_2 x_2)$$\n",
    "и его веса меняютя со значений $\\mathbf{w} = (w_0, w_1, w_2) = (0, 1/2, 1/2)$ на и значения $\\mathbf{w} = (w_0, w_1, w_2) = (1/2, 9/10, 1/10)$.\n",
    "\n",
    "<center> \n",
    "    <img src=\"./img/deepnet_15.png\" alt=\"Пример\" style=\"width: 600px;\"/>\n",
    "    <strong>Пример успешной работы стохастического градиентного спуска</strong>     \n",
    "</center>\n",
    "\n",
    "* а — структура первого слоя сети и входные распределения\n",
    "* б — результат для двух разных векторов весов\n",
    "\n",
    "Ситуация с точки зрения нейронов следующего уровня:\n",
    "* сначала на вход получали одно распределение (серый график) и обучились на нем\n",
    "* потом, когда вектор весов сильно сместился и то, чему обучились нейроны второго уровня, стало почти бесполезным: входы теперь берутся из совершенно новой области, и обучаться надо фактически заново\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сопутствующая проблема: __\"насыщение\" функций активации__\n",
    "\n",
    "<center> \n",
    "    <img src=\"./img/ann_17.png\" alt=\"Пример\" style=\"width: 500px;\"/>\n",
    "    <strong>Производные популярных функций активации</strong>     \n",
    "</center>\n",
    "\n",
    "Часто в нейронных сетях используются сигмоидальные функции активации ($f(x) =\\sigma (x)$, $f(x) =\\tanh (x)$), одной из особенностей которых является __\"насыщение\" значений функций активации__:\n",
    "* когда входы получают большие по модулю значения производная $f'(x)$ быстро стремится к 0\n",
    "* отрциательное следствие: при близких к 0 производных обратное распространение ошибки очень сильно затухает на этих градиетнтах\n",
    "* потенциальное решение: замена функций активации на $ReLU$, но это не единственный и не всегда подходящий способ\n",
    "\n",
    "В частности, при внутреннем сдвиге переменных высока вероятность насыщения функций активации и возникновения существенных сложностей при обучении глубоких моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Проблема сдвига переменных не является специфической сугубо для глубоких нейронных сетей. \n",
    "* В классическом машинном обучении распространена аналогичная проблема:\n",
    "    * распределение данных в тестовой выборке существенно отличается от распределения данных в обучающей выборке\n",
    "    \n",
    "* Наиболее распространенный метод решения: __нормализация данных__\n",
    "* Для классических нейронных сетей эта процедура выглядела как «отбелевание» (whitened) входов сети:\n",
    "    * среднее значение входных данных приведится к нулю\n",
    "    * матрица ковариаций приводится к единичной матрице\n",
    "\n",
    "Нормализация входов часто помогает, и прежде чем обучать нейронную сеть, ее желательно делать. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нормализация входов часто помогает, и прежде чем обучать нейронную сеть, ее желательно делать.\n",
    "\n",
    "__(гипотеза):__ нормировать входы очередного слоя внутри сети на каждом шаге обучения:\n",
    "* если не учитывать эту операцию при обучении это приведт к неадекватному изменению весов (например, констант)\n",
    "* <em class=\"hn\"></em> нужно учитывать нормализацию при градиентном спуске\n",
    "\n",
    "Прямолинейнвый подход:\n",
    "\n",
    "Введем слой нормализации:\n",
    "$\\hat{\\mathbf{x}}=Norm(\\mathbf{x}, \\mathcal{X})$\n",
    "\n",
    "где $\\mathbf{x}$ - текущий обучающий пример, а $\\mathcal{X}$ - все примеры из тренировочной выборки (!).\n",
    "* <em class=\"hn\"></em> для шага градиентного спуска нам необходимо вычислить якобианы для $\\dfrac{\\partial Norm}{\\partial \\mathbf{\\mathbf{x}}}$ и $\\dfrac{\\partial Norm}{\\partial \\mathbf{\\mathcal{X}}}$, причем рассчитывать второй якобиан точно прийдется!\n",
    "* для операции «отбеливания» (декорреляции) потребуется вычислить матрицу ковариаций:\n",
    "$$Cov[x] = \\mathbb{E}_{\\mathbf{x} \\in \\mathcal{X}} [\\mathbf{x}\\mathbf{x}^⊤] − \\mathbb{E}[x] \\mathbb{E}[x]^⊤$$\n",
    "затем обратить ее и вычислить из нее квадратный корень, а при градиентном спуске еще и производные такого преобразования.\n",
    "\n",
    "Полноценную декорреляцию для каждого слоя __сделать за разумное время невозможно__, особенно для больших датасетов, поэтому используются __упрощенные варианты__:\n",
    "\n",
    "Вместо декорреляции всех входов совместно, нормализуют каждый элемент входного вектора по отдельности:\n",
    "\n",
    "Представим $\\mathbf{x}=(x_1,\\ldots,x_d)$, тогда нормализация компоненты вектора выглядит так:\n",
    "$$\\hat{x}_k = \\frac{x_k-\\mathbb{E}[x_k]}{\\sqrt{Var(x_k)}}$$\n",
    "\n",
    "Среднее и дисперсию в формуле хотелось нужно вычислять по всему датасету $\\mathcal{X}$, но это совершенно невозможно вычислительно, поэтому применим очередное упрощение: будем рассичитывать эти виличины по текущему мини-батчу. Данный подход называется __нормализацией по мини-батчам__. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Недостатки нормализации по мини-батчам:\n",
    "\n",
    "* Если используется сигмоидная функция активации (например: $f(x) =\\sigma (x)$, $f(x) =\\tanh (x)$), то после нормализации ее аргумента нелинейность по сути пропадает\n",
    "    * т.к. подавляющее большинство нормализованных значений будут попадать в область, где сигмоид ведет себя очень похоже на линейную функцию, и функция активации фактически станет линейной\n",
    "    \n",
    "<center> \n",
    "    <img src=\"./img/ann_6.png\" alt=\"Графиики функций активации\" style=\"width: 600px;\"/>\n",
    "    <strong>Графиики функций активации</strong>     \n",
    "</center>    \n",
    "\n",
    "Для исправления этого недостатка, слой нормализации должен иметь возможность \"настроиться\" как тождественная функция. Т.е. при некоторых комбинациях параметров он должен работать как $f(x)=x$.\n",
    "* для этого введем параметры $\\gamma_k$ и $\\beta_k$ для масштабирования и сдвига нормализованной aктивации по каждой компоненте:\n",
    "$$y_k=\\gamma_k \\hat{x}_k + beta_k= \\gamma_k \\frac{x_k-\\mathbb{E}[x_k]}{\\sqrt{Var(x_k)}}+ \\beta_k$$\n",
    "* параметры $\\gamma_k$ и $\\beta_k$ будут обучаться вместе со всеми  параметрами ИНС и позволяют восстановить выразительную способность сети в целом\n",
    "* в частности, при настройке значений $\\gamma_k=\\sqrt{Var(x_k)}$ и $\\beta_k=\\mathbb{E}[x_k]$ слой нормализации может обучиться реализовывать тождественную функцию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Резюмируем описание работы слоя нормализации по мини-батчам:\n",
    "1. Слой получает на вход очередной мини-батч $B = \\{\\mathbf{x}_1, \\ldots ,\\mathbf{x}_m\\}$\n",
    "2. Вычисляются базовые статистики по мини-батчу: \n",
    "$$\\mu_B=\\frac{1}{m}\\sum_{i=1}^{m}\\mathbf{x}_i\\text{, }\\sigma_B^2=\\frac{1}{m}\\sum_{i=1}^{m}(\\mathbf{x}_i-\\mu_B)^2$$\n",
    "3. Нормализует выходы:\n",
    "$$\\hat{x}_k = \\gamma_k \\frac{x_k-\\mu_B}{\\sqrt{\\sigma_B^2+\\epsilon}}+ \\beta_k$$\n",
    "небольшая положительная константа $\\epsilon$ необходима для того, чтобы избежать деления на 0\n",
    "4. Рассчитывате результат:\n",
    "$$y_k=\\gamma_k \\hat{x}_k + \\beta_k$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<center> \n",
    "    <img src=\"./img/deepnet_16.png\" alt=\"Пример\" style=\"width: 600px;\"/>\n",
    "    <strong>Пример нормализации до и после нелинейности</strong>         \n",
    "</center>\n",
    "* а — графы вычислений\n",
    "* б — соответствующие результаты сэмплирования\n",
    "\n",
    "На данный момент нет устоявшегося мнения по вопросу о том, лучше делать ее после очередного слоя или после линейной\n",
    "части слоя, до нелинейной функции активации. Различные варианты дают разный эффект, в частности:\n",
    "* область значений в варианте нормализации после сигмоидальной нелинейности будет шире\n",
    "* область значений в варианте нормализации после сигмоидальной нелинейности будет уже, т.к. $\\tanh$ или $\\sigma$ снова вернут нормализованные результаты на отрезок [−1,1] или [0,1] соответственно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример использования нормализации по батчам в PyTorch:\n",
    "```python\n",
    "class network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(network, self).__init__()\n",
    "        self.linear1 = nn.Linear(in_features=40, out_features=320)\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=320)\n",
    "        self.linear2 = nn.Linear(in_features=320, out_features=2)\n",
    "\n",
    "    def forward(self, input):  # Input is a 1D tensor\n",
    "        y = F.relu(self.bn1(self.linear1(input)))\n",
    "        y = F.softmax(self.linear2(y), dim=1)\n",
    "        return y\n",
    "    \n",
    "model = network()\n",
    "x = torch.randn(10, 40)\n",
    "output = model(x)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Документация по слою нормализации в Keras:\n",
    "\n",
    "https://keras.io/layers/normalization/\n",
    "\n",
    "Пример использования слоев нормализации по батчам:\n",
    "\n",
    "https://www.programcreek.com/python/example/100588/keras.layers.normalization.BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Усовершенствованные методы градиентного супска\n",
    "\n",
    "* __Метод градиентныого спуска__ - метод нахождения локального экстремума (минимума или максимума) функции с помощью движения вдоль градиента. В нашем случае шаг метода градиентного спуска выглядит следующим образом:\n",
    "$$\\pmb{\\theta}_t = \\pmb{\\theta}_{t-1}-\\eta\\nabla_\\theta E(\\pmb{\\theta}_{t-1}) = \\pmb{\\theta}_{t-1}-\\eta \\sum_{(\\pmb{x}, \\pmb{y}) \\in D} \\nabla_\\theta E(f_L(\\pmb{x}, \\pmb{\\theta}), \\pmb{y})$$\n",
    "* (!) Выполнение на каждом шаге градиентого спуска суммирование по всем $(\\pmb{x}, \\pmb{y}) \\in D$ обычно слшиком неэффективно\n",
    "\n",
    "* Для выпуклых функций __задача локальной оптимизации__ - найти локальный минимум (максимум) автоматически превращается в __задачу глобальной оптимизации__ - найти точку, в которой достигается наименьшее (наибольшее) значение функции, то есть самую низкую (высокую) точку среди всех.\n",
    "* Оптимизировать веса одного перцептрона - выпуклая задача, но __для большой нейронной сети  целевая функция не является выпуклой__.\n",
    "\n",
    "<center> \n",
    "    <img src=\"./img/ann_15.png\" alt=\"Пример работы градиентного спуска\" style=\"width: 500px;\"/>\n",
    "    <strong>Пример работы градиентного спуска для функции двух переменных</strong>     \n",
    "</center>\n",
    "\n",
    "У нейронных сетей функция ошибки может задавать очень сложный ландшафт с огромным числом локальных максимумов и минимумов. Это свойство необходимо для обеспечения выразительности нейронных сетей, позволяющей им решать так много разных задач."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Градиентный спуск с изменяемой скоростью обучения__\n",
    "\n",
    "Параметр метода  градиентного спуска: скорость обучения $\\eta$ показывает, насколько сильно мы сдвигаем параметры\n",
    "в сторону градиента на очередном шаге.\n",
    "\n",
    "Скорость обучения — это чрезвычайно важный параметр. \n",
    "* Если она будет слишком большой: \n",
    "    * алгоритм станет \"прыгать\" по практически случайным точкам пространства и не попадет в минимум, потому что все время будет его \"перепрыгивать\"\n",
    "* Еесли она будет слишком маленькой: \n",
    "    * обучение станет гораздо медленнее\n",
    "    * алгоритм рискует успокоиться и сойтись в первом же локальном минимуме, который скорее всего не окажется самым лучшим.\n",
    "\n",
    "<center> \n",
    "    <img src=\"./img/deepnet_18.png\" alt=\"шаг градиентного спуска\" style=\"width: 500px;\"/>\n",
    "    <strong>Последствия неверного выбора шага градиентного спуска</strong>     \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Простейшая стратегия управления скоростью обучения:\n",
    "* сначала скорость обучения должна быть большой: это позволяет быстрее прийти в правильную область пространства поиска\n",
    "* затем корость обучения должна быть маленькой: это позволяет детально исследовать окрестности точки минимума и в итоге попасть в нее\n",
    "\n",
    "Реализация в виде линейного затухания:\n",
    "$$\\eta=\\eta_0 \\left ( 1- \\frac{t}{T}\\right )$$\n",
    "\n",
    "Реализация в виде экспоненциального затухания:\n",
    "$$\\eta=\\eta_0 e^{-\\frac{t}{T}}$$\n",
    "\n",
    "где $t$ — это время прошедшее с начала обучения время (число мини-батчей или число эпох обучения), а $T$ — параметр, определяющий, как быстро будет уменьшаться $\\eta$.\n",
    "\n",
    "* правильный подбор $\\eta_0$ и $T$ позволяет существенно улчшить градиентный спуск\n",
    "* как правильно подобрать $\\eta_0$ и $T$?\n",
    "Если правильно подобрать параметры $\\eta_0$ и $T$, такая стратегия будет почти наверняка работать лучше, чем градиентный спуск с постоянной скоростью, а если повезет, то и вообще работать будет хорошо."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Адаптивные методы градиентного спуска__\n",
    "\n",
    "* Замедление обучения с фиксированными параметрами никак не учитывает характиристики оптимзируемой функции\n",
    "* __Адаптивные методы градиентного спуска__ меняют параметры ГС в зависимости от результатов взаимодействия с оптимизируемой функцией\n",
    "\n",
    "Пример:\n",
    "\n",
    "В местах, где поверхность функции больше наклонена в одном измерении, чем в другом, обычный стохастический градиентный спуск может вести себя некорректно. Например, если минимум находится в сильно вытянутом«овраге»:\n",
    "* шаг градиентного спуска будет направлен от одной близкой и крутой стенки этого оврага к другой\n",
    "* когда точка попадет на другую стенку, градиент станет направлен в противоположную сторону\n",
    "* т.е. в процессе оптимизации текущее решение будет \"прыгать\" между стенками оврага, но к общему минимуму будет продвигаться очень медленно\n",
    "\n",
    "<center> \n",
    "    <img src=\"./img/deepnet_19.png\" alt=\"Пример работы градиентного спуска\" style=\"width: 500px;\"/>\n",
    "    <strong>Пример неэффективной работы не адаптивного градиентного спуска</strong>     \n",
    "</center>\n",
    "\n",
    "В этой ситуации можгут помочь адаптивные методы градиентного спуска:\n",
    "\n",
    "<center> \n",
    "    <img src=\"./img/deepnet_17.png\" alt=\"Пример работы градиентного спуска\" style=\"width: 500px;\"/>\n",
    "    <strong>Пример работы градиентного спуска для функции двух переменных</strong>     \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Метод импульсов__\n",
    "\n",
    "Идея метода импульс (momentum): точка не просто подчиняется правилам градиентного спуска, а подчиняется законам механики, в первую очередь имеет инерцеию, т.е.:\n",
    "* у точки есть скорость\n",
    "* положение точки на следующем шаге определяется ее текущим положением и скоростью\n",
    "* ускорение (скорость изменения скорости) определяется величиной градиента\n",
    "* на каждом шаге пересчитывается как положение точки, так и ее скорость\n",
    "\n",
    "Т.е. у точки, которая спускается по поверхности, появляется импульс, она движется по\n",
    "инерции и стремится этот импульс сохранить (отсюда и название метода). \n",
    "\n",
    "Формальная запись метода импульсов:\n",
    "$$\\pmb{\\theta}_t = \\pmb{\\theta}_{t-1}-u_t$$\n",
    "$$u_t=\\gamma u_{t-1} + \\eta\\nabla_\\theta E(\\pmb{\\theta}_{t-1})$$\n",
    "\n",
    "здесь:\n",
    "* $u_t$ - скорость точки в момент времени $t$ \n",
    "* $\\gamma$ - параметр метода моментов:\n",
    "    * параметр определяет, какую часть прошлого градиента мы хотим сохранить на текущем шаге\n",
    "    * $\\gamma<1$    \n",
    "\n",
    "* Теперь, когда точка \"катится с горки\", и все больше ускоряется в том направлении, в котором были направлены сразу несколько предыдущих градиентов, но будет двигаться достаточно медленно в тех направлениях, где градиент все время меняется. \n",
    "* <em class=\"hn\"></em> Метод импульсов помогает ускорить градиентный спуск в нужном направлении и уменьшает его колебания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Метод Нестерова__\n",
    "\n",
    "Метод Нестерова улучшает метод импульсов. При расчетах на шаге $t$ для получения $\\pmb{\\theta}_t$ : \n",
    "* вместо расчета градиента значения функции ошибки в точке $\\pmb{\\theta}_{t-1}$ (как было в методе моментов)\n",
    "* метод Нестерова рассчитывает градиента значения функции ошибки в точке $\\pmb{\\theta}_{t-1}-\\gamma u_{t-1}$\n",
    "\n",
    "Т.е. вместо:\n",
    "$$\\pmb{\\theta}_t = \\pmb{\\theta}_{t-1}-u_t=\\pmb{\\theta}_{t-1}-\\gamma u_{t-1} - \\eta\\nabla_\\theta E(\\pmb{\\theta}_{t-1})$$\n",
    "рассматриваем:\n",
    "$$\\pmb{\\theta}_t = \\pmb{\\theta}_{t-1}-u_t=\\pmb{\\theta}_{t-1}-\\gamma u_{t-1} - \\eta\\nabla_\\theta E(\\pmb{\\theta}_{t-1}-\\gamma u_{t-1})$$\n",
    "\n",
    "<center> \n",
    "    <img src=\"./img/deepnet_20.png\" alt=\"Методы импульсов\" style=\"width: 350px;\"/>\n",
    "    <strong>Визуализация двух вариантов метода импульсов</strong>     \n",
    "</center>\n",
    "\n",
    "Это целесообразно, т.к.:\n",
    "* огласно методу моментов $\\gamma u_{t-1}$ уже точно будет использовано на этом шаге\n",
    "* изменившийся градент разумно считать уже в той точке, куда мы придем после применения момента предыдущего шага"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Метод Adagrad__\n",
    "\n",
    "В рассмотренных выше адаптивных методах\n",
    "* шаг обновления зависел только от текущего градиента и глобальных параметров\n",
    "* шаг обновления не учитывал историю обновлений для каждого отдельного параметра\n",
    "\n",
    "Возможный вариант:\n",
    "* некоторые веса уже близки к своим локальным минимумам <em class=\"hn\"></em> по этим координатам нужно двигаться медленно\n",
    "* другие веса еще находятся \"на крутом склоне\" <em class=\"hn\"></em> их можно менять гораздо быстрее\n",
    "\n",
    "В методах, которые мы обсуждали до сих пор, шаг обновления зависел только от текущего градиента и глобального параметра скорости обучения, но никак не учитывал историю обновлений для каждого отдельного параметра. Однако вполне может так сложиться, что некоторые веса уже близки к своим локальным минимумам, и по этим координатам нужно двигаться медленно и осторожно, а другие веса еще на середине соответствующего склона, и их можно менять гораздо быстрее. К тому же, само по себе регулирование скорости обучения может оказаться довольно затратным делом. Для того чтобы иметь возможность адаптировать скорость обучения для разных параметров автоматически, были созданы адаптивные методы оптимизации.\n",
    "\n",
    "Идея метода __Adagrad__:\n",
    "* шаг изменения должен быть меньше у параметров, которые в большей степени варьируются в данных\n",
    "* шаг изменения должен быть больше у тех, которые менее изменчивы в разных примерах\n",
    "\n",
    "Обозначим через $g_{t,i}$ градиент функции ошибки по параметру $θ_i$ на шаге $t$:\n",
    "$$g_{t,i} = \\nabla_{\\theta_i} E(\\pmb{\\theta}_{t})$$.\n",
    "\n",
    "Тогда обновление параметра $\\theta_i$ на очередном шаге градиентного спуска можно записать так:\n",
    "\n",
    "$$\\theta_{t+1,i}=\\theta_{t,i}-\\frac{\\eta}{\\sqrt{G_{t,ii}+\\epsilon}} \\cdot g_{t,i}$$\n",
    "\n",
    "где $G_{t}$ - диагональная матрица, каждый элемент которой - сумма квадратов градиентов соответствующего параметра за предыдущие шаги:\n",
    "\n",
    "$$G_{t,ii}=G_{t-1,ii}+g_{t,i}^2$$\n",
    "а $\\epsilon$ - сглаживающий параметр, позволяющий избежать деления на ноль.\n",
    "\n",
    "В вектороном виде выражения можно записать (произведение выполняется покомпонентно):\n",
    "$$\\pmb{u_t}=-\\frac{\\eta}{\\sqrt{G_{t-1}+\\epsilon}} \\odot g_{t-1}$$\n",
    "\n",
    "* <em class=\"pl\"></em> Один из плюсов Adagrad является снятие необходимости ручной настройки скорости обучения $\\eta$ т.к. диагональные элементы $G$ по сути являются индивидуальными скоростями обучения для каждого компонента $\\pmb{\\theta}$.\n",
    "* <em class=\"mn\"></em> Т.к. слагаемое $g^2$ всегда положительно <em class=\"hn\"></em> $G$ постоянно увеличивается <em class=\"hn\"></em> скорость оптимизации (обучения) может уменьшаться слишком быстро, что плохо сказывается на обучении глубоких ИНС\n",
    "* <em class=\"mn\"></em> Глобальную скорость обучения в Adagrad нужно выбирать вручную"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Adadelta__ -  несложная, но эффективная модификация алгоритма Adagrad, основная цель которой состоит в том, чтобы попытаться исправить два указанных выше недостатка.\n",
    "\n",
    "Первая идея: избавиться от накаплиения суммы квадратов градиентов по всей истории обучения\n",
    "* (I вариант) будем считать суммы квадратов градиентов по некоторому окну\n",
    "* (II вариант) будем считать суммы квадратов градиентов по всей истории, но с экспоненциально затухающими весами\n",
    "\n",
    "Для каждого оптимизируемого параметра введем свой метапараметр $\\rho_i$, тогда экспоненциальное затухание можно записать так:\n",
    "\n",
    "$$G_{t,ii}=\\rho G_{t-1,ii}+(1-\\rho)g_{t,i}^2$$\n",
    "\n",
    "при этом, как и в методе моментов, метапараметр $\\rho_i<1$\n",
    "\n",
    "* Экспоненциальное среднее, в отличие от суммы, будет убывать только тогда, когда убывающими станут градиенты.\n",
    "* Т.е. уменьшение скорости обучения будет происходить только в тот момент, когда изменение целевой функции замедляется, для более тонкой настройки вокруг локального минимума.\n",
    "\n",
    "Вторая идея: исправление размерности в шаге алгоритма\n",
    "\n",
    "* В Adagrad значения обновлений $\\Delta \\theta $ зависят от отношений градиентов, то есть величина обновлений являюется безразмерной. \n",
    "* Правильные \"единицы измерений\" получаются только в методах второго порядка. В частности в методе Ньютона второго порядка обновление параметров: \n",
    "$$\\Delta \\theta \\sim H^{-1}\\nabla_{\\theta}f \\sim \\frac{\\dfrac{\\partial f}{\\partial \\theta}}{\\dfrac{\\partial^2 f}{\\partial \\theta^2}} \\sim размерность \\theta$$\n",
    "\n",
    "* Чтобы привести масштабы этих величин в соответствие, достаточно домножить обновление из Adagrad на еще один новый сомножитель: еще одно экспоненциальное среднее, но теперь уже от квадратов обновлений параметров, а не от градиента.\n",
    "* Поскольку настоящее среднее квадратов обновлений нам неизвестно, то чтобы его узнать, нам нужно как раз сначала выполнить текущий шаг алгоритма, — оно аппроксимируется предыдущими шагами:\n",
    "$$\\mathbb{E} \\left [ \\Delta \\theta^2\\right ]_t=\\rho \\mathbb{E} \\left [ \\Delta \\theta^2\\right ]_{t-1}+(1-\\rho)\\Delta \\theta^2$$\n",
    "С помощью полученного значения получаем поправочных коэффициент:\n",
    "$$\\pmb{u_t}=-\\frac{\\sqrt{\\mathbb{E} \\left [ \\Delta \\theta^2\\right ]_{t-1}+\\epsilon}}{\\sqrt{G_{t-1}+\\epsilon}} \\odot \\pmb{g_{t-1}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существует близкий аналог Adadelta алгоритм RMSprop оба метода основаны на классической идее применения инерции, только  RMSprop использует ее для оптимизации метапараметра скорости обучения.\n",
    "\n",
    "Основная разница между RMSprop и Adadelta состоит в том, что RMSprop не делает вторую поправку с изменением единиц и хранением истории самих обновлений, а просто использует корень из среднего от квадратов (вот он где, RMS) от\n",
    "градиентов:\n",
    "\n",
    "$$\\pmb{u_t}=-\\frac{\\eta}{\\sqrt{G_{t-1}+\\epsilon}} \\odot g_{t-1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> \n",
    "    <img src=\"./img/opt2.gif\" alt=\"Пример работы градиентного спуска\" style=\"width: 500px;\"/>\n",
    "    <strong>Пример работы различных вариантов градиентного спуска для функции двух переменных</strong>     \n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Методы оптимизации, доступные в Pytorch: https://pytorch.org/docs/stable/optim.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Спасибо за внимание!\n",
    "\n",
    "---\n",
    "### Технический раздел:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/> next <em class=\"qs\"></em> qs line \n",
    "<br/> next <em class=\"an\"></em> an line \n",
    "<br/> next <em class=\"nt\"></em> an line \n",
    "<br/> next <em class=\"df\"></em> df line \n",
    "<br/> next <em class=\"ex\"></em> ex line \n",
    "<br/> next <em class=\"pl\"></em> pl line \n",
    "<br/> next <em class=\"mn\"></em> mn line \n",
    "<br/> next <em class=\"plmn\"></em> plmn line \n",
    "<br/> next <em class=\"hn\"></em> hn line "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
