{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "u49LZV9dKFWi",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn.functional as F\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def make_confusion_matrix(loader,model, labels,device):\n",
    "    with torch.inference_mode():\n",
    "        test_p= []\n",
    "        test_grs=[]\n",
    "        for x,y in loader:\n",
    "            x=x.to(device)\n",
    "            preds= model(x)\n",
    "            test_p += list(torch.argmax(preds,dim=1).cpu())\n",
    "            test_grs += list(y)\n",
    "    plt.figure(figsize=(12,9))\n",
    "    sns.heatmap(confusion_matrix(test_grs, test_p),\n",
    "          xticklabels= labels, yticklabels= labels, \n",
    "          cmap= \"viridis\",annot= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_acc(predictions, grs):\n",
    "    predictions= torch.softmax(predictions,dim=1)\n",
    "    predictions=torch.argmax(predictions,dim=1)\n",
    "    acc= (torch.sum(predictions==grs)/len(grs)).item()\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import notebook_tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def classification(train_loader,test_loader, model \n",
    "                   , criterion, optimizer, epochs, device= 'cpu'): #criterion - функция ошибок, random model\n",
    "    train_loss_h=[]\n",
    "    test_loss_h=[]\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_loss=0.0\n",
    "        train_acc=0.0\n",
    "        test_loss=0.0\n",
    "        test_acc=0.0\n",
    "        model.train()\n",
    "        \n",
    "        for x,y in train_loader: #x-картина\n",
    "            x,y = x.to(device), y.to(device) \n",
    "            optimizer.zero_grad()\n",
    "            pred=model(x) \n",
    "            loss=criterion(pred,y)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            train_acc += calculate_acc(pred,y)\n",
    "            train_loss /= len(train_loader)\n",
    "            train_acc /= len(train_loader)\n",
    "            train_loss_h.append(train_loss)\n",
    "            \n",
    "        with torch.inference_mode():\n",
    "            model.eval()\n",
    "            for x,y in test_loader:\n",
    "                x.to(device),y.to(device) \n",
    "                test_pred=model(x)\n",
    "                test_loss+=criterion(test_pred,y).item()\n",
    "                test_acc+=calculate_acc(test_pred,y)\n",
    "        test_loss/=len(train_loader)\n",
    "        test_acc/=len(train_loader)\n",
    "        test_loss_h.append(train_loss)\n",
    "        print('epoch: ', epoch, '|Train loss= ', train_loss,'Acc train= ', train_acc,  '|test loss= ', test_loss,'Acc test= ', test_acc )\n",
    "    return train_loss_h,test_loss_h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "403Mis3LAgED"
   },
   "source": [
    "## 1. Классификация предметов одежды (датасет Fashion MNIST)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mn6r8tMDQsaU"
   },
   "source": [
    "\n",
    "### 1.1 Решить задачу классификации, не используя сверточные слои  CNN. \n",
    "* Предложить архитектуру модели для решения задачи\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MNIST_TRAIN = torchvision.datasets.MNIST(\"data\", download = True)\n",
    "MNIST_TEST = torchvision.datasets.MNIST(\"data\", download = True, train = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Mnistdataset(Dataset):\n",
    "  def __init__(self, train: bool = True, transforms = None):\n",
    "    if train:\n",
    "      self.X = MNIST_TRAIN.data\n",
    "      self.y = MNIST_TRAIN.targets\n",
    "    else:\n",
    "      self.X = MNIST_TEST.data\n",
    "      self.y = MNIST_TEST.targets\n",
    "    self.transforms = transforms\n",
    "  def __len__(self):\n",
    "    return self.X.shape[0]\n",
    "  def __getitem__(self, index:int):\n",
    "    x = self.X[index]\n",
    "    y = self.y[index]\n",
    "    if self.transforms:\n",
    "      x = self.transforms(x)\n",
    "    x = torch.flatten(x)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mnist_transforms = torchvision.transforms.Compose([transforms.ConvertImageDtype(torch.float32),]) \n",
    "\n",
    "train_mnist_dataset = Mnistdataset(train=True, transforms = mnist_transforms)\n",
    "test_mnist_dataset = Mnistdataset(train=False, transforms = mnist_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_mnist_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_mnist_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f500ce56e50>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[0].numpy().reshape(28,28), cmap = \"Greys_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Ourmodel(nn.Module):\n",
    "    def __init__(self, n_f, hid, out):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(n_f, hid)\n",
    "        self.l2= nn.Linear(hid, hid*2)\n",
    "        self.l3 = nn.Linear(hid*2, out)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        out1 = self.relu(self.l1(inputs))\n",
    "        out2 = self.relu(self.l2(out1))\n",
    "        out3 = self.l3(out2)\n",
    "        return out3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Посчитать количество параметров модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16950"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our = Ourmodel(28*28, 20,10)\n",
    "sum(p.shape[0]*p.shape[1] if len(p.shape)==2 else p.shape[0] for p in our.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Обучить модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_ = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(our.parameters(), lr = 0.01)\n",
    "N = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 |Train loss=  0.000335527607649871 Acc train=  0.0004002579295548454 |test loss=  0.04623066163311402 Acc test=  0.15436666666666668\n",
      "epoch:  1 |Train loss=  0.00010091945176674706 Acc train=  0.0005002756931179861 |test loss=  0.04006296348520555 Acc test=  0.156\n",
      "epoch:  2 |Train loss=  4.651291283167941e-05 Acc train=  0.0005335912581423798 |test loss=  0.039596769477116565 Acc test=  0.1562\n",
      "epoch:  3 |Train loss=  0.0002870142006162328 Acc train=  0.00043359125815249075 |test loss=  0.04265273302781085 Acc test=  0.15493333333333334\n",
      "epoch:  4 |Train loss=  0.00015113543561845604 Acc train=  0.0004836090406684836 |test loss=  0.03533469748261074 Acc test=  0.15713333333333335\n",
      "epoch:  5 |Train loss=  0.00018443613139012055 Acc train=  0.00048360903593027527 |test loss=  0.044652367218708 Acc test=  0.15516666666666667\n",
      "epoch:  6 |Train loss=  0.00021069713108481036 Acc train=  0.0005002668042215121 |test loss=  0.03902347152127574 Acc test=  0.15681666666666666\n",
      "epoch:  7 |Train loss=  0.0001483262258164003 Acc train=  0.0005002756978561999 |test loss=  0.039783638484217225 Acc test=  0.15693333333333334\n",
      "epoch:  8 |Train loss=  2.4851162761631565e-05 Acc train=  0.0005336090311870061 |test loss=  0.052240812806940325 Acc test=  0.15356666666666666\n",
      "epoch:  9 |Train loss=  7.97153908056755e-05 Acc train=  0.0005002756978561999 |test loss=  0.038119835439293336 Acc test=  0.1572\n",
      "epoch:  10 |Train loss=  0.00015853511132821969 Acc train=  0.00048361792955484677 |test loss=  0.044842884860932825 Acc test=  0.1564\n",
      "epoch:  11 |Train loss=  5.9491002025792664e-05 Acc train=  0.0005169423645228665 |test loss=  0.04554519806460788 Acc test=  0.15538333333333335\n",
      "epoch:  12 |Train loss=  9.485231224636577e-05 Acc train=  0.0005169423740043466 |test loss=  0.039738130442022034 Acc test=  0.15731666666666666\n",
      "epoch:  13 |Train loss=  0.0003027908966523391 Acc train=  0.0004836179200784221 |test loss=  0.04292930615997563 Acc test=  0.15668333333333334\n",
      "epoch:  14 |Train loss=  0.00011849710871589755 Acc train=  0.0005002668137080503 |test loss=  0.04218608282376081 Acc test=  0.15671666666666667\n",
      "epoch:  15 |Train loss=  0.00010656127989767384 Acc train=  0.0005002668137080516 |test loss=  0.04577666524350643 Acc test=  0.15663333333333335\n",
      "epoch:  16 |Train loss=  0.0002737902021170257 Acc train=  0.00046694236452286516 |test loss=  0.040734374397931 Acc test=  0.15598333333333333\n",
      "epoch:  17 |Train loss=  1.3095557953897847e-05 Acc train=  0.0005336090311870061 |test loss=  0.041294602303983026 Acc test=  0.15726666666666667\n",
      "epoch:  18 |Train loss=  5.110171851482651e-05 Acc train=  0.0005169423645253962 |test loss=  0.04494394968690273 Acc test=  0.15665\n",
      "epoch:  19 |Train loss=  0.00012318958111026115 Acc train=  0.0005002579295573765 |test loss=  0.04236849085455761 Acc test=  0.15628333333333333\n"
     ]
    }
   ],
   "source": [
    "history_train, history_test = classification(train_loader, test_loader, our, loss_, optimizer,N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Вывести график функции потерь по эпохам. \n",
    "* Используя тестовое множество\n",
    "\n",
    "  * Продемонстрировать работу модели: вывести несколько изображений, указать над ними правильный класс и класс, предсказанный моделью. \n",
    "\n",
    "  * Вывести матрицу ошибок.\n",
    "\n",
    "  * Вывести значение accuracy на тестовом множестве.\n",
    "* Сохранить модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNISTDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GmsMQUPP-XUh"
   },
   "source": [
    "### 1.2 Решить задачу 1.1, используя сверточную нейронную сеть. \n",
    "* Добиться значения accuracy на тестовом множестве не менее 90%\n",
    "* Визуализировать результаты работы первого сверточного слоя"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cm6_9B3ZKLq9"
   },
   "source": [
    "##  2. Классификация изображений (датасет CIFAR 10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VNTZa9yWQvSF"
   },
   "source": [
    "\n",
    "### 2.1 Решить задачу классификации, не используя сверточные слои. \n",
    "\n",
    "* Нормализовать данные (если необходимо)\n",
    "* Предложить архитектуру модели для решения задачи\n",
    "* Посчитать количество параметров модели.\n",
    "* Обучить модель\n",
    "* Вывести график функции потерь по эпохам. \n",
    "* Используя тестовое множество\n",
    "\n",
    "  * Продемонстрировать работу модели: вывести несколько изображений, указать над ними правильный класс и класс, предсказанный моделью. \n",
    "\n",
    "  * Вывести матрицу ошибок.\n",
    "\n",
    "  * Вывести значение accuracy на тестовом множестве.\n",
    "* Сохранить модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class OurmodelCNN(nn.Module):\n",
    "    def __init__(self, n_f, hid, out):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Covn2d(inputcanal, hid)\n",
    "        self.l2= nn.Linear(hid, hid*2)\n",
    "        self.l3 = nn.Linear(hid*2, out)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        out1 = self.relu(self.l1(inputs))\n",
    "        out2 = self.relu(self.l2(out1))\n",
    "        out3 = self.l3(out2)\n",
    "        return out3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix\n\u001b[0;32m----> 2\u001b[0m confusion_matrix(\u001b[43my_test\u001b[49m, y_test_pred)\n\u001b[1;32m      3\u001b[0m plot_confusion_matrix(model, X_test, y_test, cmap\u001b[38;5;241m=\u001b[39mplt\u001b[38;5;241m.\u001b[39mcm\u001b[38;5;241m.\u001b[39mBlues)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_test_pred)\n",
    "plot_confusion_matrix(model, X_test, y_test, cmap=plt.cm.Blues)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IIxHLbKcDCFA"
   },
   "source": [
    "### 2.2 Решить задачу 2.1, используя сверточную нейронную сеть. \n",
    "* Добиться значения accuracy на тестовом множестве не менее 70%.\n",
    "* Визуализировать результаты работы первого сверточного слоя"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nPg8k4YTFOgc"
   },
   "source": [
    "## 3. Загрузка изображений из внешних источников"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1hLnpe_570wd"
   },
   "source": [
    "### 3.1 Решить задачу классификации обезьян (датасет [monkey.zip](https://disk.yandex.ru/d/OxYgY4S7aR6ulQ)).\n",
    "* Загрузить архив с данными на диск\n",
    "* Создать датасет на основе файлов при помощи `torchvision.datasets.ImageFolder`\n",
    "* Преобразовать изображения к тензорами одного размера (например, 400х400). Потестировать другие преобразования из `torchvision.transforms`\n",
    "* Предложить архитектуру модели для решения задачи. Обучить модель.\n",
    "* Используя тестовое множество\n",
    "\n",
    "  * Продемонстрировать работу модели: вывести несколько изображений, указать над ними правильный класс и класс, предсказанный моделью. \n",
    "\n",
    "  * Вывести матрицу ошибок.\n",
    "\n",
    "  * Вывести значение accuracy на тестовом множестве.\n",
    "  * Добиться значения accuracy на тестовом множестве не менее 60%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 506,
     "status": "ok",
     "timestamp": 1616695933807,
     "user": {
      "displayName": "Никита Блохин",
      "photoUrl": "",
      "userId": "16402972581398673009"
     },
     "user_tz": -180
    },
    "id": "iXnzblkFFN5K",
    "outputId": "cbbabfdc-a8c4-41c6-86a8-f7e99748a612"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17268,
     "status": "ok",
     "timestamp": 1616695954172,
     "user": {
      "displayName": "Никита Блохин",
      "photoUrl": "",
      "userId": "16402972581398673009"
     },
     "user_tz": -180
    },
    "id": "4Er_FLV6Hrqq",
    "outputId": "5ece4316-16e6-458c-eb94-c0604e19ea24"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "zf = zipfile.ZipFile('drive/MyDrive/datasets/monkeys.zip')\n",
    "for file in tqdm(zf.infolist()):\n",
    "    zf.extract(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5-tMy4qJ9j1k"
   },
   "source": [
    "### 3.2 Решить задачу классификации собак и кошек (датасет [cats_dogs.zip](https://disk.yandex.ru/d/wQtt5O1JF9ctnA)).\n",
    "* Загрузить архив с данными на диск\n",
    "* Создать датасет на основе файлов при помощи `torchvision.datasets.ImageFolder`\n",
    "* Преобразовать изображения к тензорами одного размера (например, 400х400). Потестировать другие преобразования из `torchvision.transforms`\n",
    "* Предложить архитектуру модели для решения задачи. Обучить модель.\n",
    "* Используя тестовое множество\n",
    "\n",
    "  * Продемонстрировать работу модели: вывести несколько изображений, указать над ними правильный класс и класс, предсказанный моделью. \n",
    "\n",
    "  * Вывести матрицу ошибок.\n",
    "\n",
    "  * Вывести значение accuracy на тестовом множестве.\n",
    "  * Добиться значения accuracy на тестовом множестве не менее 80%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EqvleAgxfC6B"
   },
   "source": [
    "# 4. Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZjNUwuho9tm9"
   },
   "source": [
    "### 4.1 Решить задачу 3.1, воспользовавшись предобученной моделью VGG16\n",
    "* Загрузить данные для обучения\n",
    "* Преобразования: размер 224x224, нормализация с параметрами `mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)`\n",
    "* Заменить последний полносвязный слой модели в соответствии с задачей\n",
    "* Дообучить модель (не замораживать веса). Вычислить значение accuracy на тестовом множестве\n",
    "* Дообучить модель (заморозить все веса, кроме последнего блока слоев (`classifier`)). \n",
    "* Вычислить значение accuracy на тестовом множестве.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dt_hXy5a5CE8"
   },
   "source": [
    "### 4.2 Решить задачу 3.2, воспользовавшись подходящей предобученной моделью\n",
    "* Не использовать VGG16 (вместо нее можно взять resnet18 или другую)\n",
    "* Загрузить данные для обучения\n",
    "* Преобразования: размер 224x224, нормализация с параметрами `mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)`\n",
    "* Заменить последний полносвязный слой модели в соответствии с задачей\n",
    "* Дообучить модель. \n",
    "* Вычислить значение accuracy на тестовом множестве (добиться значения не меньше 97-98%)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMF+zO/4VvRSXLWjIV8BHI2",
   "collapsed_sections": [],
   "name": "blank_04_cnn.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
