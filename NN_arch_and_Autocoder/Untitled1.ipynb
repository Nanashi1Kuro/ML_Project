{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10178b3d-c5a7-44f8-9ce2-5285779a8bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab667d53-a3ac-4b5d-a35f-0a0dd15532e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/device:CPU:0', '/device:GPU:0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-20 15:28:42.622081: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-20 15:28:42.622328: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-20 15:28:42.622447: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-20 15:28:42.622610: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-20 15:28:42.622726: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-20 15:28:42.622825: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /device:GPU:0 with 373 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "import tensorflow\n",
    "\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "\n",
    "print(get_available_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a8f7310-dcf5-46de-aa76-3b0b45f95168",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loc = '/home/chris/Downloads/AI_course/NN_arch_and_Autocoder/Face_Mask_Dataset/Train'\n",
    "test_loc = '/home/chris/Downloads/AI_course/NN_arch_and_Autocoder/Face_Mask_Dataset/Test'\n",
    "validation_loc = '/home/chris/Downloads/AI_course/NN_arch_and_Autocoder/Face_Mask_Dataset/Validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "abc979a1-33a3-4e34-a863-48fd16e2a729",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = glob(train_loc + '/*/*.p*g')\n",
    "valid_image_files = glob(test_loc + '/*/*.p*g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec108f88-004f-48b6-bf04-74e218c1c0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Classes = 2\n"
     ]
    }
   ],
   "source": [
    "folders = glob(train_loc + '/*')\n",
    "num_classes = len(folders)\n",
    "print ('Total Classes = ' + str(num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ac00b766-e1e1-49ab-83cc-ebc9862feeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "from keras.models import Model\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras.applications import VGG16\n",
    "#from keras.preprocessing import image\n",
    "\n",
    "IMAGE_SIZE = [64, 64]  # we will keep the image size as (64,64). You can increase the size for better results. \n",
    "\n",
    "# loading the weights of VGG16 without the top layer. These weights are trained on Imagenet dataset.\n",
    "vgg = VGG16(input_shape = IMAGE_SIZE + [3], weights = 'imagenet', include_top = False)  # input_shape = (64,64,3) as required by VGG\n",
    "\n",
    "# this will exclude the initial layers from training phase as there are already been trained.\n",
    "for layer in vgg.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = Flatten()(vgg.output)\n",
    "#x = Dense(128, activation = 'relu')(x)   # we can add a new fully connected layer but it will increase the execution time.\n",
    "x = Dense(num_classes, activation = 'softmax')(x)  # adding the output layer with softmax function as this is a multi label classification problem.\n",
    "\n",
    "model = Model(inputs = vgg.input, outputs = x)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "23eb034f-9486-4a07-b553-aa34b8a6740a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 64, 64, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 64, 64, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 32, 32, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 32, 32, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 16, 16, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 16, 16, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 16, 16, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 8, 8, 512)         1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 4098      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,718,786\n",
      "Trainable params: 4,098\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b742fcf2-8fb2-4fee-b25f-38f4da078e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 images belonging to 2 classes.\n",
      "Found 993 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "training_datagen = ImageDataGenerator(\n",
    "                                    rescale=1./255,   # all pixel values will be between 0 an 1\n",
    "                                    shear_range=0.2, \n",
    "                                    zoom_range=0.2,\n",
    "                                    horizontal_flip=True,\n",
    "                                    preprocessing_function=preprocess_input)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale = 1./255, preprocessing_function=preprocess_input)\n",
    "\n",
    "training_generator = training_datagen.flow_from_directory(train_loc, target_size = IMAGE_SIZE, batch_size = 200, class_mode = 'categorical')\n",
    "validation_generator = validation_datagen.flow_from_directory(test_loc, target_size = IMAGE_SIZE, batch_size = 200, class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ddea9315-f104-4ecd-a0a3-031ef5683270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'WithMask': 0, 'WithoutMask': 1}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6134266b-2bc5-4bce-bf4a-4870fcc631eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8775/2296220682.py:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-20 15:29:12.833448: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-07-20 15:29:23.810364: W tensorflow/tsl/framework/bfc_allocator.cc:485] Allocator (GPU_0_bfc) ran out of memory trying to allocate 200.00MiB (rounded to 209715200)requested by op model_2/block1_conv1/Relu\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-07-20 15:29:23.810544: I tensorflow/tsl/framework/bfc_allocator.cc:1039] BFCAllocator dump for GPU_0_bfc\n",
      "2023-07-20 15:29:23.810666: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (256): \tTotal Chunks: 63, Chunks in use: 62. 15.8KiB allocated for chunks. 15.5KiB in use in bin. 1.8KiB client-requested in use in bin.\n",
      "2023-07-20 15:29:23.810724: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (512): \tTotal Chunks: 6, Chunks in use: 6. 3.5KiB allocated for chunks. 3.5KiB in use in bin. 3.0KiB client-requested in use in bin.\n",
      "2023-07-20 15:29:23.810776: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1024): \tTotal Chunks: 11, Chunks in use: 11. 13.0KiB allocated for chunks. 13.0KiB in use in bin. 11.6KiB client-requested in use in bin.\n",
      "2023-07-20 15:29:23.810826: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2048): \tTotal Chunks: 19, Chunks in use: 19. 41.5KiB allocated for chunks. 41.5KiB in use in bin. 37.6KiB client-requested in use in bin.\n",
      "2023-07-20 15:29:23.810874: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4096): \tTotal Chunks: 3, Chunks in use: 3. 20.2KiB allocated for chunks. 20.2KiB in use in bin. 20.2KiB client-requested in use in bin.\n",
      "2023-07-20 15:29:23.810921: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-20 15:29:23.810973: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16384): \tTotal Chunks: 9, Chunks in use: 9. 144.0KiB allocated for chunks. 144.0KiB in use in bin. 144.0KiB client-requested in use in bin.\n",
      "2023-07-20 15:29:23.811018: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-20 15:29:23.811061: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-20 15:29:23.811103: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-20 15:29:23.811153: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (262144): \tTotal Chunks: 6, Chunks in use: 6. 2.08MiB allocated for chunks. 2.08MiB in use in bin. 1.27MiB client-requested in use in bin.\n",
      "2023-07-20 15:29:23.811200: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (524288): \tTotal Chunks: 4, Chunks in use: 3. 2.56MiB allocated for chunks. 1.69MiB in use in bin. 1.69MiB client-requested in use in bin.\n",
      "2023-07-20 15:29:23.811247: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1048576): \tTotal Chunks: 3, Chunks in use: 3. 4.57MiB allocated for chunks. 4.57MiB in use in bin. 3.38MiB client-requested in use in bin.\n",
      "2023-07-20 15:29:23.811298: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2097152): \tTotal Chunks: 6, Chunks in use: 6. 13.50MiB allocated for chunks. 13.50MiB in use in bin. 13.50MiB client-requested in use in bin.\n",
      "2023-07-20 15:29:23.811346: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4194304): \tTotal Chunks: 3, Chunks in use: 3. 13.50MiB allocated for chunks. 13.50MiB in use in bin. 13.50MiB client-requested in use in bin.\n",
      "2023-07-20 15:29:23.811396: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8388608): \tTotal Chunks: 16, Chunks in use: 16. 145.50MiB allocated for chunks. 145.50MiB in use in bin. 144.38MiB client-requested in use in bin.\n",
      "2023-07-20 15:29:23.811439: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-20 15:29:23.811481: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-20 15:29:23.811522: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-20 15:29:23.811579: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (134217728): \tTotal Chunks: 1, Chunks in use: 0. 191.99MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-20 15:29:23.811623: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-20 15:29:23.811669: I tensorflow/tsl/framework/bfc_allocator.cc:1062] Bin for 200.00MiB was 128.00MiB, Chunk State: \n",
      "2023-07-20 15:29:23.811736: I tensorflow/tsl/framework/bfc_allocator.cc:1068]   Size: 191.99MiB | Requested Size: 0B | in_use: 0 | bin_num: 19, prev:   Size: 9.38MiB | Requested Size: 9.38MiB | in_use: 1 | bin_num: -1\n",
      "2023-07-20 15:29:23.811775: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 392101888\n",
      "2023-07-20 15:29:23.811822: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48000000 of size 1280 next 1\n",
      "2023-07-20 15:29:23.811864: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48000500 of size 256 next 2\n",
      "2023-07-20 15:29:23.811904: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48000600 of size 256 next 3\n",
      "2023-07-20 15:29:23.811942: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48000700 of size 256 next 5\n",
      "2023-07-20 15:29:23.811978: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48000800 of size 256 next 6\n",
      "2023-07-20 15:29:23.812015: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48000900 of size 256 next 4\n",
      "2023-07-20 15:29:23.812051: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48000a00 of size 256 next 7\n",
      "2023-07-20 15:29:23.812087: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48000b00 of size 256 next 12\n",
      "2023-07-20 15:29:23.812123: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48000c00 of size 256 next 10\n",
      "2023-07-20 15:29:23.812159: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48000d00 of size 256 next 11\n",
      "2023-07-20 15:29:23.812199: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48000e00 of size 512 next 15\n",
      "2023-07-20 15:29:23.812239: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48001000 of size 256 next 16\n",
      "2023-07-20 15:29:23.812277: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48001100 of size 256 next 19\n",
      "2023-07-20 15:29:23.812315: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48001200 of size 256 next 50\n",
      "2023-07-20 15:29:23.812373: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48001300 of size 256 next 22\n",
      "2023-07-20 15:29:23.812415: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48001400 of size 256 next 20\n",
      "2023-07-20 15:29:23.812453: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48001500 of size 256 next 21\n",
      "2023-07-20 15:29:23.812526: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48001600 of size 1024 next 25\n",
      "2023-07-20 15:29:23.812573: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48001a00 of size 256 next 26\n",
      "2023-07-20 15:29:23.812803: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48001b00 of size 256 next 29\n",
      "2023-07-20 15:29:23.812968: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48001c00 of size 1024 next 32\n",
      "2023-07-20 15:29:23.812987: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48002000 of size 256 next 48\n",
      "2023-07-20 15:29:23.813000: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48002100 of size 256 next 53\n",
      "2023-07-20 15:29:23.813011: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48002200 of size 256 next 56\n",
      "2023-07-20 15:29:23.813025: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48002300 of size 256 next 35\n",
      "2023-07-20 15:29:23.813037: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48002400 of size 256 next 30\n",
      "2023-07-20 15:29:23.813048: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48002500 of size 256 next 31\n",
      "2023-07-20 15:29:23.813063: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48002600 of size 2048 next 37\n",
      "2023-07-20 15:29:23.813078: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48002e00 of size 256 next 38\n",
      "2023-07-20 15:29:23.813092: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48002f00 of size 256 next 41\n",
      "2023-07-20 15:29:23.813105: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48003000 of size 2048 next 44\n",
      "2023-07-20 15:29:23.813117: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48003800 of size 2048 next 8\n",
      "2023-07-20 15:29:23.813129: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48004000 of size 256 next 54\n",
      "2023-07-20 15:29:23.813141: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48004100 of size 512 next 17\n",
      "2023-07-20 15:29:23.813154: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48004300 of size 1024 next 28\n",
      "2023-07-20 15:29:23.813166: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48004700 of size 2048 next 39\n",
      "2023-07-20 15:29:23.813177: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48004f00 of size 2048 next 49\n",
      "2023-07-20 15:29:23.813189: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48005700 of size 2048 next 51\n",
      "2023-07-20 15:29:23.813201: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48005f00 of size 256 next 57\n",
      "2023-07-20 15:29:23.813214: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48006000 of size 256 next 59\n",
      "2023-07-20 15:29:23.813226: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48006100 of size 256 next 60\n",
      "2023-07-20 15:29:23.813237: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48006200 of size 256 next 61\n",
      "2023-07-20 15:29:23.813249: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48006300 of size 256 next 62\n",
      "2023-07-20 15:29:23.813261: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48006400 of size 256 next 63\n",
      "2023-07-20 15:29:23.813273: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48006500 of size 256 next 64\n",
      "2023-07-20 15:29:23.813289: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48006600 of size 256 next 65\n",
      "2023-07-20 15:29:23.813301: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48006700 of size 256 next 67\n",
      "2023-07-20 15:29:23.813314: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48006800 of size 768 next 66\n",
      "2023-07-20 15:29:23.813327: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48006b00 of size 1024 next 84\n",
      "2023-07-20 15:29:23.813339: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48006f00 of size 1024 next 52\n",
      "2023-07-20 15:29:23.813352: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48007300 of size 256 next 47\n",
      "2023-07-20 15:29:23.813365: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48007400 of size 6912 next 42\n",
      "2023-07-20 15:29:23.813378: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48008f00 of size 281600 next 14\n",
      "2023-07-20 15:29:23.813391: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e4804db00 of size 442368 next 18\n",
      "2023-07-20 15:29:23.813406: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e480b9b00 of size 2064384 next 23\n",
      "2023-07-20 15:29:23.813420: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e482b1b00 of size 589824 next 13\n",
      "2023-07-20 15:29:23.813432: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48341b00 of size 4718592 next 33\n",
      "2023-07-20 15:29:23.813446: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e487c1b00 of size 16384 next 58\n",
      "2023-07-20 15:29:23.813460: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e487c5b00 of size 16384 next 55\n",
      "2023-07-20 15:29:23.813472: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e487c9b00 of size 16384 next 24\n",
      "2023-07-20 15:29:23.813484: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e487cdb00 of size 2048 next 85\n",
      "2023-07-20 15:29:23.813497: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e487ce300 of size 2048 next 69\n",
      "2023-07-20 15:29:23.813510: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e487ceb00 of size 2048 next 90\n",
      "2023-07-20 15:29:23.813522: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e487cf300 of size 2048 next 93\n",
      "2023-07-20 15:29:23.813533: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e487cfb00 of size 2048 next 95\n",
      "2023-07-20 15:29:23.813546: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e487d0300 of size 3584 next 70\n",
      "2023-07-20 15:29:23.813559: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e487d1100 of size 256 next 76\n",
      "2023-07-20 15:29:23.813571: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e487d1200 of size 512 next 74\n",
      "2023-07-20 15:29:23.813583: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e487d1400 of size 1024 next 81\n",
      "2023-07-20 15:29:23.813595: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e487d1800 of size 256 next 99\n",
      "2023-07-20 15:29:23.813608: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e487d1900 of size 256 next 68\n",
      "2023-07-20 15:29:23.813619: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e487d1a00 of size 256 next 98\n",
      "2023-07-20 15:29:23.813631: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e487d1b00 of size 256 next 86\n",
      "2023-07-20 15:29:23.813643: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e487d1c00 of size 256 next 102\n",
      "2023-07-20 15:29:23.813656: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e487d1d00 of size 256 next 103\n",
      "2023-07-20 15:29:23.813667: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e487d1e00 of size 256 next 104\n",
      "2023-07-20 15:29:23.813679: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e487d1f00 of size 256 next 105\n",
      "2023-07-20 15:29:23.813694: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e487d2000 of size 256 next 106\n",
      "2023-07-20 15:29:23.813706: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e487d2100 of size 256 next 72\n",
      "2023-07-20 15:29:23.813718: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e487d2200 of size 256 next 100\n",
      "2023-07-20 15:29:23.813729: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e487d2300 of size 256 next 107\n",
      "2023-07-20 15:29:23.813742: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e487d2400 of size 256 next 111\n",
      "2023-07-20 15:29:23.813754: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e487d2500 of size 768 next 109\n",
      "2023-07-20 15:29:23.813766: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e487d2800 of size 1536 next 122\n",
      "2023-07-20 15:29:23.813778: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e487d2e00 of size 1536 next 89\n",
      "2023-07-20 15:29:23.813791: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e487d3400 of size 6912 next 97\n",
      "2023-07-20 15:29:23.813803: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e487d4f00 of size 285952 next 73\n",
      "2023-07-20 15:29:23.813816: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e4881ac00 of size 442368 next 75\n",
      "2023-07-20 15:29:23.813828: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48886c00 of size 589824 next 120\n",
      "2023-07-20 15:29:23.813841: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48916c00 of size 1474560 next 78\n",
      "2023-07-20 15:29:23.813853: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48a7ec00 of size 589824 next 71\n",
      "2023-07-20 15:29:23.813865: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48b0ec00 of size 16384 next 101\n",
      "2023-07-20 15:29:23.813881: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48b12c00 of size 16384 next 83\n",
      "2023-07-20 15:29:23.813893: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48b16c00 of size 16384 next 87\n",
      "2023-07-20 15:29:23.813905: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48b1ac00 of size 3072 next 129\n",
      "2023-07-20 15:29:23.813918: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48b1b800 of size 2048 next 121\n",
      "2023-07-20 15:29:23.813930: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48b1c000 of size 2048 next 128\n",
      "2023-07-20 15:29:23.813943: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48b1c800 of size 2048 next 134\n",
      "2023-07-20 15:29:23.813954: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48b1d000 of size 2048 next 136\n",
      "2023-07-20 15:29:23.813966: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48b1d800 of size 256 next 133\n",
      "2023-07-20 15:29:23.813978: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48b1d900 of size 256 next 139\n",
      "2023-07-20 15:29:23.813990: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48b1da00 of size 256 next 141\n",
      "2023-07-20 15:29:23.814006: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48b1db00 of size 256 next 113\n",
      "2023-07-20 15:29:23.814018: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48b1dc00 of size 256 next 114\n",
      "2023-07-20 15:29:23.814030: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48b1dd00 of size 256 next 142\n",
      "2023-07-20 15:29:23.814041: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48b1de00 of size 256 next 143\n",
      "2023-07-20 15:29:23.814053: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48b1df00 of size 256 next 144\n",
      "2023-07-20 15:29:23.814065: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48b1e000 of size 256 next 145\n",
      "2023-07-20 15:29:23.814077: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48b1e100 of size 256 next 112\n",
      "2023-07-20 15:29:23.814089: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48b1e200 of size 256 next 140\n",
      "2023-07-20 15:29:23.814101: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48b1e300 of size 512 next 116\n",
      "2023-07-20 15:29:23.814113: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48b1e500 of size 1024 next 124\n",
      "2023-07-20 15:29:23.814125: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48b1e900 of size 2048 next 131\n",
      "2023-07-20 15:29:23.814137: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48b1f100 of size 3072 next 108\n",
      "2023-07-20 15:29:23.814149: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48b1fd00 of size 6912 next 138\n",
      "2023-07-20 15:29:23.814163: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48b21800 of size 288000 next 115\n",
      "2023-07-20 15:29:23.814175: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48b67d00 of size 442368 next 117\n",
      "2023-07-20 15:29:23.814187: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48bd3d00 of size 16384 next 119\n",
      "2023-07-20 15:29:23.814199: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48bd7d00 of size 16384 next 123\n",
      "2023-07-20 15:29:23.814212: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48bdbd00 of size 16384 next 127\n",
      "2023-07-20 15:29:23.814224: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f1e48bdfd00 of size 256 next 147\n",
      "2023-07-20 15:29:23.814236: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48bdfe00 of size 256 next 148\n",
      "2023-07-20 15:29:23.814248: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48bdff00 of size 1792 next 149\n",
      "2023-07-20 15:29:23.814260: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f1e48be0600 of size 910848 next 80\n",
      "2023-07-20 15:29:23.814274: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48cbec00 of size 1257216 next 36\n",
      "2023-07-20 15:29:23.814287: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e48df1b00 of size 2359296 next 27\n",
      "2023-07-20 15:29:23.814299: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e49031b00 of size 2359296 next 40\n",
      "2023-07-20 15:29:23.814311: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e49271b00 of size 9437184 next 34\n",
      "2023-07-20 15:29:23.814324: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e49b71b00 of size 9437184 next 46\n",
      "2023-07-20 15:29:23.814337: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e4a471b00 of size 9437184 next 45\n",
      "2023-07-20 15:29:23.814349: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e4ad71b00 of size 9437184 next 9\n",
      "2023-07-20 15:29:23.814361: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e4b671b00 of size 9437184 next 43\n",
      "2023-07-20 15:29:23.814373: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e4bf71b00 of size 2359296 next 77\n",
      "2023-07-20 15:29:23.814385: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e4c1b1b00 of size 2359296 next 79\n",
      "2023-07-20 15:29:23.814396: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e4c3f1b00 of size 4718592 next 82\n",
      "2023-07-20 15:29:23.814408: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e4c871b00 of size 9437184 next 88\n",
      "2023-07-20 15:29:23.814421: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e4d171b00 of size 9437184 next 92\n",
      "2023-07-20 15:29:23.814433: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e4da71b00 of size 9437184 next 91\n",
      "2023-07-20 15:29:23.814445: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e4e371b00 of size 9437184 next 94\n",
      "2023-07-20 15:29:23.814457: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e4ec71b00 of size 9437184 next 96\n",
      "2023-07-20 15:29:23.814468: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e4f571b00 of size 2359296 next 110\n",
      "2023-07-20 15:29:23.814480: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e4f7b1b00 of size 2359296 next 126\n",
      "2023-07-20 15:29:23.814492: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e4f9f1b00 of size 9437184 next 118\n",
      "2023-07-20 15:29:23.814505: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e502f1b00 of size 10616832 next 130\n",
      "2023-07-20 15:29:23.814519: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e50d11b00 of size 4718592 next 125\n",
      "2023-07-20 15:29:23.814531: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e51191b00 of size 9437184 next 132\n",
      "2023-07-20 15:29:23.814543: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e51a91b00 of size 9437184 next 135\n",
      "2023-07-20 15:29:23.814555: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e52391b00 of size 9437184 next 137\n",
      "2023-07-20 15:29:23.814567: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1e52c91b00 of size 9830400 next 146\n",
      "2023-07-20 15:29:23.814581: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f1e535f1b00 of size 201319680 next 18446744073709551615\n",
      "2023-07-20 15:29:23.814595: I tensorflow/tsl/framework/bfc_allocator.cc:1100]      Summary of in-use Chunks by size: \n",
      "2023-07-20 15:29:23.814634: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 62 Chunks of size 256 totalling 15.5KiB\n",
      "2023-07-20 15:29:23.814651: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 4 Chunks of size 512 totalling 2.0KiB\n",
      "2023-07-20 15:29:23.814669: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 768 totalling 1.5KiB\n",
      "2023-07-20 15:29:23.814682: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 7 Chunks of size 1024 totalling 7.0KiB\n",
      "2023-07-20 15:29:23.814696: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2023-07-20 15:29:23.814709: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 1536 totalling 3.0KiB\n",
      "2023-07-20 15:29:23.814723: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1792 totalling 1.8KiB\n",
      "2023-07-20 15:29:23.814738: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 16 Chunks of size 2048 totalling 32.0KiB\n",
      "2023-07-20 15:29:23.814751: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 3072 totalling 6.0KiB\n",
      "2023-07-20 15:29:23.814764: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 3584 totalling 3.5KiB\n",
      "2023-07-20 15:29:23.814778: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 6912 totalling 20.2KiB\n",
      "2023-07-20 15:29:23.814793: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 9 Chunks of size 16384 totalling 144.0KiB\n",
      "2023-07-20 15:29:23.814807: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 281600 totalling 275.0KiB\n",
      "2023-07-20 15:29:23.814822: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 285952 totalling 279.2KiB\n",
      "2023-07-20 15:29:23.814836: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 288000 totalling 281.2KiB\n",
      "2023-07-20 15:29:23.814850: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 442368 totalling 1.27MiB\n",
      "2023-07-20 15:29:23.814864: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 589824 totalling 1.69MiB\n",
      "2023-07-20 15:29:23.814877: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1257216 totalling 1.20MiB\n",
      "2023-07-20 15:29:23.814891: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1474560 totalling 1.41MiB\n",
      "2023-07-20 15:29:23.814904: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 2064384 totalling 1.97MiB\n",
      "2023-07-20 15:29:23.814918: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 6 Chunks of size 2359296 totalling 13.50MiB\n",
      "2023-07-20 15:29:23.814932: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 4718592 totalling 13.50MiB\n",
      "2023-07-20 15:29:23.814946: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 14 Chunks of size 9437184 totalling 126.00MiB\n",
      "2023-07-20 15:29:23.814961: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 9830400 totalling 9.38MiB\n",
      "2023-07-20 15:29:23.814975: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 10616832 totalling 10.12MiB\n",
      "2023-07-20 15:29:23.814991: I tensorflow/tsl/framework/bfc_allocator.cc:1107] Sum Total of in-use chunks: 181.08MiB\n",
      "2023-07-20 15:29:23.815006: I tensorflow/tsl/framework/bfc_allocator.cc:1109] Total bytes in pool: 392101888 memory_limit_: 392101888 available bytes: 0 curr_region_allocation_bytes_: 784203776\n",
      "2023-07-20 15:29:23.815035: I tensorflow/tsl/framework/bfc_allocator.cc:1114] Stats: \n",
      "Limit:                       392101888\n",
      "InUse:                       189871104\n",
      "MaxInUse:                    388317440\n",
      "NumAllocs:                         466\n",
      "MaxAllocSize:                315745536\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-07-20 15:29:23.815118: W tensorflow/tsl/framework/bfc_allocator.cc:497] *************************************************___________________________________________________\n",
      "2023-07-20 15:29:23.815183: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at conv_ops_fused_impl.h:772 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[200,64,64,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "2023-07-20 15:29:23.815265: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:GPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[200,64,64,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "\t [[{{node model_2/block1_conv1/Relu}}]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
      "\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'model_2/block1_conv1/Relu' defined at (most recent call last):\n    File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/chris/.local/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/chris/.local/lib/python3.8/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/home/chris/.local/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 728, in start\n      self.io_loop.start()\n    File \"/home/chris/.local/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/chris/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"/home/chris/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"/home/chris/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n      await result\n    File \"/home/chris/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n      reply_content = await reply_content\n    File \"/home/chris/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/home/chris/.local/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/chris/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/home/chris/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/home/chris/.local/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/chris/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/chris/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/chris/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_8775/2296220682.py\", line 4, in <module>\n      history = model.fit_generator(\n    File \"/home/chris/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 2636, in fit_generator\n      return self.fit(\n    File \"/home/chris/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/chris/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/chris/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/home/chris/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/chris/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/home/chris/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1050, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/chris/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/chris/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/chris/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/chris/.local/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/chris/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/chris/.local/lib/python3.8/site-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/chris/.local/lib/python3.8/site-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/chris/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/chris/.local/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/chris/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/chris/.local/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py\", line 321, in call\n      return self.activation(outputs)\n    File \"/home/chris/.local/lib/python3.8/site-packages/keras/activations.py\", line 317, in relu\n      return backend.relu(\n    File \"/home/chris/.local/lib/python3.8/site-packages/keras/backend.py\", line 5396, in relu\n      x = tf.nn.relu(x)\nNode: 'model_2/block1_conv1/Relu'\nOOM when allocating tensor with shape[200,64,64,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_2/block1_conv1/Relu}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_4013]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m validation_images \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m800\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tensorflow\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/GPU:0\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_generator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtraining_generator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py:2636\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2624\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[1;32m   2625\u001b[0m \n\u001b[1;32m   2626\u001b[0m \u001b[38;5;124;03mDEPRECATED:\u001b[39;00m\n\u001b[1;32m   2627\u001b[0m \u001b[38;5;124;03m  `Model.fit` now supports generators, so there is no longer any need to\u001b[39;00m\n\u001b[1;32m   2628\u001b[0m \u001b[38;5;124;03m  use this endpoint.\u001b[39;00m\n\u001b[1;32m   2629\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2630\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   2631\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Model.fit_generator` is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2632\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future version. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2633\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2634\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   2635\u001b[0m )\n\u001b[0;32m-> 2636\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2637\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2638\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2639\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2640\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2641\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2648\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2650\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2651\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model_2/block1_conv1/Relu' defined at (most recent call last):\n    File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/chris/.local/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/chris/.local/lib/python3.8/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/home/chris/.local/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 728, in start\n      self.io_loop.start()\n    File \"/home/chris/.local/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/chris/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"/home/chris/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"/home/chris/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n      await result\n    File \"/home/chris/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n      reply_content = await reply_content\n    File \"/home/chris/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/home/chris/.local/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/chris/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/home/chris/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/home/chris/.local/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/chris/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/chris/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/chris/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_8775/2296220682.py\", line 4, in <module>\n      history = model.fit_generator(\n    File \"/home/chris/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 2636, in fit_generator\n      return self.fit(\n    File \"/home/chris/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/chris/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/chris/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/home/chris/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/chris/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/home/chris/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1050, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/chris/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/chris/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/chris/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/chris/.local/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/chris/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/chris/.local/lib/python3.8/site-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/chris/.local/lib/python3.8/site-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/chris/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/chris/.local/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/chris/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/chris/.local/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py\", line 321, in call\n      return self.activation(outputs)\n    File \"/home/chris/.local/lib/python3.8/site-packages/keras/activations.py\", line 317, in relu\n      return backend.relu(\n    File \"/home/chris/.local/lib/python3.8/site-packages/keras/backend.py\", line 5396, in relu\n      x = tf.nn.relu(x)\nNode: 'model_2/block1_conv1/Relu'\nOOM when allocating tensor with shape[200,64,64,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_2/block1_conv1/Relu}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_4013]"
     ]
    }
   ],
   "source": [
    "training_images = 10000\n",
    "validation_images = 800\n",
    "with tensorflow.device('/GPU:0'):\n",
    "    history = model.fit_generator(\n",
    "        training_generator,\n",
    "        validation_data = validation_generator,\n",
    "        epochs = 50,\n",
    "        steps_per_epoch = len(training_generator),\n",
    "        validation_steps = len(validation_generator)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29641f3-b4a4-4666-ae10-e457f9cab33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Training Accuracy = ' + str(history.history['acc']))\n",
    "print ('Validation Accuracy = ' + str(history.history['val_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2822b5a-5e2a-4c45-a9e2-ed052ba2fedc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc582491-1a7e-4d7c-89d9-da762f43234d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
